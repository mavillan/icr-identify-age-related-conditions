{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791e4da7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:02.642056Z",
     "iopub.status.busy": "2023-07-01T05:55:02.641700Z",
     "iopub.status.idle": "2023-07-01T05:55:06.166866Z",
     "shell.execute_reply": "2023-07-01T05:55:06.165797Z"
    },
    "papermill": {
     "duration": 3.533363,
     "end_time": "2023-07-01T05:55:06.169359",
     "exception": false,
     "start_time": "2023-07-01T05:55:02.635996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavillan/mambaforge/envs/kg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_contour\n",
    "    , plot_edf\n",
    "    , plot_intermediate_values\n",
    "    , plot_optimization_history\n",
    "    , plot_parallel_coordinate\n",
    "    , plot_param_importances\n",
    "    , plot_slice\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b684f",
   "metadata": {
    "papermill": {
     "duration": 0.003191,
     "end_time": "2023-07-01T05:55:06.176449",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.173258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783b3296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.184568Z",
     "iopub.status.busy": "2023-07-01T05:55:06.184039Z",
     "iopub.status.idle": "2023-07-01T05:55:06.294671Z",
     "shell.execute_reply": "2023-07-01T05:55:06.293600Z"
    },
    "papermill": {
     "duration": 0.117124,
     "end_time": "2023-07-01T05:55:06.296616",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.179492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>BZ</th>\n",
       "      <th>CB</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CF</th>\n",
       "      <th>CH</th>\n",
       "      <th>CL</th>\n",
       "      <th>CR</th>\n",
       "      <th>CS</th>\n",
       "      <th>CU</th>\n",
       "      <th>CW</th>\n",
       "      <th>DA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DF</th>\n",
       "      <th>DH</th>\n",
       "      <th>DI</th>\n",
       "      <th>DL</th>\n",
       "      <th>DN</th>\n",
       "      <th>DU</th>\n",
       "      <th>DV</th>\n",
       "      <th>DY</th>\n",
       "      <th>EB</th>\n",
       "      <th>EE</th>\n",
       "      <th>EG</th>\n",
       "      <th>EH</th>\n",
       "      <th>EJ</th>\n",
       "      <th>EL</th>\n",
       "      <th>EP</th>\n",
       "      <th>EU</th>\n",
       "      <th>FC</th>\n",
       "      <th>FD</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "      <th>Alpha_A</th>\n",
       "      <th>Alpha_B</th>\n",
       "      <th>Alpha_D</th>\n",
       "      <th>Alpha_G</th>\n",
       "      <th>Beta_A</th>\n",
       "      <th>Beta_B</th>\n",
       "      <th>Beta_C</th>\n",
       "      <th>Gamma_A</th>\n",
       "      <th>Gamma_B</th>\n",
       "      <th>Gamma_E</th>\n",
       "      <th>Gamma_F</th>\n",
       "      <th>Gamma_G</th>\n",
       "      <th>Gamma_H</th>\n",
       "      <th>Gamma_M</th>\n",
       "      <th>Gamma_N</th>\n",
       "      <th>Delta_A</th>\n",
       "      <th>Delta_B</th>\n",
       "      <th>Delta_C</th>\n",
       "      <th>Delta_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>175.638726</td>\n",
       "      <td>152.707705</td>\n",
       "      <td>823.928241</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>47.223358</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>23.387600</td>\n",
       "      <td>4.851915</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>13.784111</td>\n",
       "      <td>1.302012</td>\n",
       "      <td>36.205956</td>\n",
       "      <td>69.08340</td>\n",
       "      <td>295.570575</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>89.245560</td>\n",
       "      <td>84.31664</td>\n",
       "      <td>29.657104</td>\n",
       "      <td>5.310690</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>23.187704</td>\n",
       "      <td>7.294176</td>\n",
       "      <td>1.987283</td>\n",
       "      <td>1433.166750</td>\n",
       "      <td>0.949104</td>\n",
       "      <td>1</td>\n",
       "      <td>30.879420</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>13.394640</td>\n",
       "      <td>10.265073</td>\n",
       "      <td>9028.291921</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>155.868030</td>\n",
       "      <td>14.754720</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>0.484710</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.117800</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>178.553100</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>37.532000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>1111.287150</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>52.260480</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>219.320160</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>70.81970</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>11.050410</td>\n",
       "      <td>661.518640</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>88.159360</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>41.116960</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>139.824570</td>\n",
       "      <td>71.57120</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>7.386060</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>15691.552180</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>1</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>10965.766040</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>24.0108</td>\n",
       "      <td>324.546318</td>\n",
       "      <td>149.717165</td>\n",
       "      <td>6074.859475</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>82.213495</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>72.644264</td>\n",
       "      <td>30.537722</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>31.724726</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>34.415360</td>\n",
       "      <td>74.06532</td>\n",
       "      <td>200.178160</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>97.920120</td>\n",
       "      <td>52.83888</td>\n",
       "      <td>26.019912</td>\n",
       "      <td>1.144902</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>9.064856</td>\n",
       "      <td>7.350720</td>\n",
       "      <td>3.490846</td>\n",
       "      <td>1403.656300</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>91.994825</td>\n",
       "      <td>51.141336</td>\n",
       "      <td>29.102640</td>\n",
       "      <td>4.274640</td>\n",
       "      <td>16198.049590</td>\n",
       "      <td>13.666727</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>fd3dafe738fd</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>3130.05946</td>\n",
       "      <td>123.763599</td>\n",
       "      <td>9.513984</td>\n",
       "      <td>13.020852</td>\n",
       "      <td>3.499305</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>8.545512</td>\n",
       "      <td>2.804172</td>\n",
       "      <td>4157.68439</td>\n",
       "      <td>21.1860</td>\n",
       "      <td>167.877117</td>\n",
       "      <td>27.287375</td>\n",
       "      <td>365.516874</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>41.368691</td>\n",
       "      <td>0.691257</td>\n",
       "      <td>55.163024</td>\n",
       "      <td>4.780452</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>1.177525</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>40.159779</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>7.030640</td>\n",
       "      <td>21.75904</td>\n",
       "      <td>355.930925</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.445479</td>\n",
       "      <td>176.977590</td>\n",
       "      <td>90.91832</td>\n",
       "      <td>27.957928</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>2.41906</td>\n",
       "      <td>32.508604</td>\n",
       "      <td>8.015112</td>\n",
       "      <td>1.354416</td>\n",
       "      <td>495.086300</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>51.618996</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>65.821872</td>\n",
       "      <td>29.708112</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>17167.209610</td>\n",
       "      <td>9.879296</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.26092</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>8.967128</td>\n",
       "      <td>217.148554</td>\n",
       "      <td>8095.932828</td>\n",
       "      <td>24.640462</td>\n",
       "      <td>69.191944</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>fd895603f071</td>\n",
       "      <td>0.435846</td>\n",
       "      <td>5462.03438</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>46.551007</td>\n",
       "      <td>15.973224</td>\n",
       "      <td>5.979825</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>12.622906</td>\n",
       "      <td>3.777550</td>\n",
       "      <td>5654.07556</td>\n",
       "      <td>27.1887</td>\n",
       "      <td>285.628059</td>\n",
       "      <td>344.644105</td>\n",
       "      <td>505.006814</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>61.910576</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>85.233928</td>\n",
       "      <td>6.682597</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.761025</td>\n",
       "      <td>39.852923</td>\n",
       "      <td>2.146113</td>\n",
       "      <td>33.648356</td>\n",
       "      <td>43.90996</td>\n",
       "      <td>157.393715</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.437280</td>\n",
       "      <td>192.598575</td>\n",
       "      <td>123.17624</td>\n",
       "      <td>26.750080</td>\n",
       "      <td>0.648318</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>18.197092</td>\n",
       "      <td>8.976360</td>\n",
       "      <td>0.753797</td>\n",
       "      <td>1722.674025</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>114.801199</td>\n",
       "      <td>447.657600</td>\n",
       "      <td>69.343680</td>\n",
       "      <td>6.067614</td>\n",
       "      <td>18460.330020</td>\n",
       "      <td>10.910227</td>\n",
       "      <td>10.223150</td>\n",
       "      <td>1.24236</td>\n",
       "      <td>0.426699</td>\n",
       "      <td>35.896418</td>\n",
       "      <td>496.994214</td>\n",
       "      <td>3085.308063</td>\n",
       "      <td>29.648928</td>\n",
       "      <td>124.808872</td>\n",
       "      <td>0.145340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>fd8ef6377f76</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>2459.10720</td>\n",
       "      <td>130.138587</td>\n",
       "      <td>55.355778</td>\n",
       "      <td>10.005552</td>\n",
       "      <td>8.070549</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>15.408390</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5888.87769</td>\n",
       "      <td>20.4798</td>\n",
       "      <td>178.661133</td>\n",
       "      <td>103.988995</td>\n",
       "      <td>2083.880500</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>90.411867</td>\n",
       "      <td>0.708616</td>\n",
       "      <td>142.680216</td>\n",
       "      <td>7.809288</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>1.495775</td>\n",
       "      <td>0.879825</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.489590</td>\n",
       "      <td>36.807176</td>\n",
       "      <td>104.62032</td>\n",
       "      <td>223.209115</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.382620</td>\n",
       "      <td>218.915925</td>\n",
       "      <td>326.23620</td>\n",
       "      <td>26.463472</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>47.552312</td>\n",
       "      <td>9.478188</td>\n",
       "      <td>2.225112</td>\n",
       "      <td>2565.402825</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>87.397401</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>71.725584</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>5088.922912</td>\n",
       "      <td>12.029366</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>19.962092</td>\n",
       "      <td>128.896894</td>\n",
       "      <td>6474.652866</td>\n",
       "      <td>26.166072</td>\n",
       "      <td>119.559420</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>fe1942975e40</td>\n",
       "      <td>0.363205</td>\n",
       "      <td>1263.53524</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>23.685856</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>7.981959</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>7.524588</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4517.86560</td>\n",
       "      <td>19.0674</td>\n",
       "      <td>119.162529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722.377629</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>12.499760</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>122.939496</td>\n",
       "      <td>2.964975</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.583125</td>\n",
       "      <td>34.367872</td>\n",
       "      <td>1.428903</td>\n",
       "      <td>36.699352</td>\n",
       "      <td>51.04140</td>\n",
       "      <td>112.196630</td>\n",
       "      <td>0.532818</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>113.526045</td>\n",
       "      <td>96.97092</td>\n",
       "      <td>27.104928</td>\n",
       "      <td>0.510378</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>38.271840</td>\n",
       "      <td>10.078968</td>\n",
       "      <td>1.628524</td>\n",
       "      <td>1318.962875</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.706633</td>\n",
       "      <td>8.259384</td>\n",
       "      <td>38.133312</td>\n",
       "      <td>6.192291</td>\n",
       "      <td>6464.250832</td>\n",
       "      <td>8.026928</td>\n",
       "      <td>9.256996</td>\n",
       "      <td>0.78764</td>\n",
       "      <td>0.670527</td>\n",
       "      <td>24.594488</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>1965.343176</td>\n",
       "      <td>25.116750</td>\n",
       "      <td>37.155112</td>\n",
       "      <td>0.184622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ffcca4ded3bb</td>\n",
       "      <td>0.482849</td>\n",
       "      <td>2672.53426</td>\n",
       "      <td>546.663930</td>\n",
       "      <td>112.006102</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.198099</td>\n",
       "      <td>0.116928</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>7.948668</td>\n",
       "      <td>2818.01707</td>\n",
       "      <td>21.1860</td>\n",
       "      <td>306.127863</td>\n",
       "      <td>6.090490</td>\n",
       "      <td>747.474930</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>67.222974</td>\n",
       "      <td>0.644837</td>\n",
       "      <td>271.240664</td>\n",
       "      <td>10.479286</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>1.241175</td>\n",
       "      <td>2.404275</td>\n",
       "      <td>42.799438</td>\n",
       "      <td>0.915822</td>\n",
       "      <td>37.824144</td>\n",
       "      <td>35.72704</td>\n",
       "      <td>889.496905</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.172179</td>\n",
       "      <td>156.345390</td>\n",
       "      <td>82.54008</td>\n",
       "      <td>21.086160</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>24.499368</td>\n",
       "      <td>7.873752</td>\n",
       "      <td>2.374259</td>\n",
       "      <td>912.311525</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>15.960087</td>\n",
       "      <td>181.218219</td>\n",
       "      <td>78.370464</td>\n",
       "      <td>66.893232</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>5895.352262</td>\n",
       "      <td>7.745765</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.14492</td>\n",
       "      <td>0.149006</td>\n",
       "      <td>13.673940</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>6850.484442</td>\n",
       "      <td>45.745974</td>\n",
       "      <td>114.842372</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id        AB          AF          AH          AM         AR  \\\n",
       "0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688   \n",
       "1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n",
       "2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n",
       "3    043ac50845d5  0.252107  3819.65177  120.201618   77.112203   8.138688   \n",
       "4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n",
       "..            ...       ...         ...         ...         ...        ...   \n",
       "612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n",
       "613  fd895603f071  0.435846  5462.03438   85.200147   46.551007  15.973224   \n",
       "614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n",
       "615  fe1942975e40  0.363205  1263.53524   85.200147   23.685856   8.138688   \n",
       "616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n",
       "\n",
       "           AX        AY         AZ          BC          BD       BN  \\\n",
       "0    0.699861  0.025578   9.812214    5.555634  4126.58731  22.5984   \n",
       "1    3.632190  0.025578  13.517790    1.229900  5496.92824  19.4205   \n",
       "2    6.732840  0.025578  12.824570    1.229900  5135.78024  26.4825   \n",
       "3    3.685344  0.025578  11.053708    1.229900  4169.67738  23.6577   \n",
       "4    3.942255  0.054810   3.396778  102.151980  5728.73412  24.0108   \n",
       "..        ...       ...        ...         ...         ...      ...   \n",
       "612  3.499305  0.077343   8.545512    2.804172  4157.68439  21.1860   \n",
       "613  5.979825  0.025882  12.622906    3.777550  5654.07556  27.1887   \n",
       "614  8.070549  0.025578  15.408390    1.229900  5888.87769  20.4798   \n",
       "615  7.981959  0.025578   7.524588    1.229900  4517.86560  19.0674   \n",
       "616  3.198099  0.116928   3.396778    7.948668  2818.01707  21.1860   \n",
       "\n",
       "             BP          BQ           BR          BZ         CB        CC  \\\n",
       "0    175.638726  152.707705   823.928241  257.432377  47.223358  0.563481   \n",
       "1    155.868030   14.754720    51.216883  257.432377  30.284345  0.484710   \n",
       "2    128.988531  219.320160   482.141594  257.432377  32.563713  0.495852   \n",
       "3    237.282264   11.050410   661.518640  257.432377  15.201914  0.717882   \n",
       "4    324.546318  149.717165  6074.859475  257.432377  82.213495  0.536467   \n",
       "..          ...         ...          ...         ...        ...       ...   \n",
       "612  167.877117   27.287375   365.516874  257.432377  41.368691  0.691257   \n",
       "613  285.628059  344.644105   505.006814  257.432377  61.910576  0.772304   \n",
       "614  178.661133  103.988995  2083.880500  257.432377  90.411867  0.708616   \n",
       "615  119.162529         NaN   722.377629  257.432377  12.499760  0.602254   \n",
       "616  306.127863    6.090490   747.474930  257.432377  67.222974  0.644837   \n",
       "\n",
       "             CD         CF        CH        CL        CR         CS        CU  \\\n",
       "0     23.387600   4.851915  0.023482  1.050225  0.069225  13.784111  1.302012   \n",
       "1     50.628208   6.085041  0.031442  1.113875  1.117800  28.310953  1.357182   \n",
       "2     85.955376   5.376488  0.036218  1.050225  0.700350  39.364743  1.009611   \n",
       "3     88.159360   2.347652  0.029054  1.400300  0.636075  41.116960  0.722727   \n",
       "4     72.644264  30.537722  0.025472  1.050225  0.693150  31.724726  0.827550   \n",
       "..          ...        ...       ...       ...       ...        ...       ...   \n",
       "612   55.163024   4.780452  0.013930  1.177525  0.698250  40.159779  1.070298   \n",
       "613   85.233928   6.682597  0.038208  1.050225  0.761025  39.852923  2.146113   \n",
       "614  142.680216   7.809288  0.027462  1.495775  0.879825  39.364743  1.489590   \n",
       "615  122.939496   2.964975  0.022288  1.050225  0.583125  34.367872  1.428903   \n",
       "616  271.240664  10.479286  0.076018  1.241175  2.404275  42.799438  0.915822   \n",
       "\n",
       "            CW         DA          DE        DF        DH          DI  \\\n",
       "0    36.205956   69.08340  295.570575  0.238680  0.284232   89.245560   \n",
       "1    37.476568   70.79836  178.553100  0.238680  0.363489  110.581815   \n",
       "2    21.459644   70.81970  321.426625  0.238680  0.210441  120.056438   \n",
       "3    21.530392   47.27586  196.607985  0.238680  0.292431  139.824570   \n",
       "4    34.415360   74.06532  200.178160  0.238680  0.207708   97.920120   \n",
       "..         ...        ...         ...       ...       ...         ...   \n",
       "612   7.030640   21.75904  355.930925  0.238680  0.445479  176.977590   \n",
       "613  33.648356   43.90996  157.393715  0.238680  0.437280  192.598575   \n",
       "614  36.807176  104.62032  223.209115  0.238680  0.382620  218.915925   \n",
       "615  36.699352   51.04140  112.196630  0.532818  0.549333  113.526045   \n",
       "616  37.824144   35.72704  889.496905  0.238680  0.172179  156.345390   \n",
       "\n",
       "            DL         DN        DU       DV         DY         EB        EE  \\\n",
       "0     84.31664  29.657104  5.310690  1.74307  23.187704   7.294176  1.987283   \n",
       "1     75.74548  37.532000  0.005518  1.74307  17.222328   4.926396  0.858603   \n",
       "2     65.46984  28.053464  1.289739  1.74307  36.861352   7.813674  8.146651   \n",
       "3     71.57120  24.354856  2.655345  1.74307  52.003884   7.386060  3.813326   \n",
       "4     52.83888  26.019912  1.144902  1.74307   9.064856   7.350720  3.490846   \n",
       "..         ...        ...       ...      ...        ...        ...       ...   \n",
       "612   90.91832  27.957928  0.005518  2.41906  32.508604   8.015112  1.354416   \n",
       "613  123.17624  26.750080  0.648318  1.74307  18.197092   8.976360  0.753797   \n",
       "614  326.23620  26.463472  0.005518  1.74307  47.552312   9.478188  2.225112   \n",
       "615   96.97092  27.104928  0.510378  1.74307  38.271840  10.078968  1.628524   \n",
       "616   82.54008  21.086160  0.005518  1.74307  24.499368   7.873752  2.374259   \n",
       "\n",
       "               EG        EH  EJ          EL          EP          EU  \\\n",
       "0     1433.166750  0.949104   1   30.879420   78.526968    3.828384   \n",
       "1     1111.287150  0.003042   0  109.125159   95.415086   52.260480   \n",
       "2     1494.076488  0.377208   1  109.125159   78.526968    5.390628   \n",
       "3    15691.552180  0.614484   1   31.674357   78.526968   31.323372   \n",
       "4     1403.656300  0.164268   1  109.125159   91.994825   51.141336   \n",
       "..            ...       ...  ..         ...         ...         ...   \n",
       "612    495.086300  0.003042   0   51.618996   78.526968   65.821872   \n",
       "613   1722.674025  0.139932   1  109.125159  114.801199  447.657600   \n",
       "614   2565.402825  0.003042   0  109.125159   87.397401    3.828384   \n",
       "615   1318.962875  0.139932   1         NaN   99.706633    8.259384   \n",
       "616    912.311525  0.003042   0   15.960087  181.218219   78.370464   \n",
       "\n",
       "             FC         FD            FE         FI         FL        FR  \\\n",
       "0     13.394640  10.265073   9028.291921   3.583450   7.298162   1.73855   \n",
       "1     17.175984   0.296850   6785.003474  10.358927   0.173229   0.49706   \n",
       "2    224.207424   8.745201   8338.906181  11.626917   7.709560   0.97556   \n",
       "3     59.301984   7.884336  10965.766040  14.852022   6.122162   0.49706   \n",
       "4     29.102640   4.274640  16198.049590  13.666727   8.153058  48.50134   \n",
       "..          ...        ...           ...        ...        ...       ...   \n",
       "612   29.708112   0.296850  17167.209610   9.879296   0.173229   1.26092   \n",
       "613   69.343680   6.067614  18460.330020  10.910227  10.223150   1.24236   \n",
       "614   71.725584   0.296850   5088.922912  12.029366   0.173229   0.49706   \n",
       "615   38.133312   6.192291   6464.250832   8.026928   9.256996   0.78764   \n",
       "616   66.893232   0.296850   5895.352262   7.745765   0.173229   1.14492   \n",
       "\n",
       "           FS         GB          GE            GF         GH          GI  \\\n",
       "0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944   \n",
       "1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n",
       "2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n",
       "3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n",
       "4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n",
       "..        ...        ...         ...           ...        ...         ...   \n",
       "612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n",
       "613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n",
       "614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n",
       "615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n",
       "616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n",
       "\n",
       "            GL  Class  Alpha_A  Alpha_B  Alpha_D  Alpha_G  Beta_A  Beta_B  \\\n",
       "0     0.120343      1        0        1        0        0       0       0   \n",
       "1    21.978000      0        1        0        0        0       0       0   \n",
       "2     0.196941      0        1        0        0        0       0       0   \n",
       "3     0.155829      0        1        0        0        0       0       0   \n",
       "4     0.096614      1        0        0        1        0       0       1   \n",
       "..         ...    ...      ...      ...      ...      ...     ...     ...   \n",
       "612  21.978000      0        1        0        0        0       0       1   \n",
       "613   0.145340      0        1        0        0        0       0       1   \n",
       "614  21.978000      0        1        0        0        0       0       0   \n",
       "615   0.184622      0        1        0        0        0       0       0   \n",
       "616  21.978000      0        1        0        0        0       0       0   \n",
       "\n",
       "     Beta_C  Gamma_A  Gamma_B  Gamma_E  Gamma_F  Gamma_G  Gamma_H  Gamma_M  \\\n",
       "0         1        0        0        0        0        1        0        0   \n",
       "1         1        0        0        0        0        0        0        1   \n",
       "2         1        0        0        0        0        0        0        1   \n",
       "3         1        0        0        0        0        0        0        1   \n",
       "4         0        0        0        0        1        0        0        0   \n",
       "..      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "612       0        0        0        0        0        0        0        1   \n",
       "613       0        0        0        0        0        0        0        1   \n",
       "614       1        0        0        0        0        0        0        1   \n",
       "615       1        0        0        0        0        0        0        1   \n",
       "616       1        0        0        0        0        0        0        1   \n",
       "\n",
       "     Gamma_N  Delta_A  Delta_B  Delta_C  Delta_D  \n",
       "0          0        0        0        0        1  \n",
       "1          0        0        1        0        0  \n",
       "2          0        0        1        0        0  \n",
       "3          0        0        1        0        0  \n",
       "4          0        0        1        0        0  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "612        0        0        1        0        0  \n",
       "613        0        0        1        0        0  \n",
       "614        0        0        1        0        0  \n",
       "615        0        0        1        0        0  \n",
       "616        0        0        1        0        0  \n",
       "\n",
       "[617 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path = \"../data/raw\"\n",
    "\n",
    "train = pd.read_csv(f\"{input_path}/train.csv\")\n",
    "test  = pd.read_csv(f\"{input_path}/test.csv\")\n",
    "greeks = pd.read_csv(f\"{input_path}/greeks.csv\")\n",
    "\n",
    "train.columns = [col.strip() for col in train.columns]\n",
    "test.columns = [col.strip() for col in test.columns]\n",
    "\n",
    "# available features\n",
    "input_cols = train.columns[1:-1]\n",
    "categ_cols = [\"EJ\"]\n",
    "\n",
    "# we extend train with dummies from greeks\n",
    "dummies = pd.get_dummies(greeks[[\"Alpha\",\"Beta\",\"Gamma\",\"Delta\"]])\n",
    "train[dummies.columns] = dummies\n",
    "\n",
    "# encode of categorical features\n",
    "encoder = preprocessing.LabelEncoder().fit(train[\"EJ\"])\n",
    "train[\"EJ\"] = encoder.transform(train[\"EJ\"]).astype(int)\n",
    "test[\"EJ\"] = encoder.transform(test[\"EJ\"]).astype(int)\n",
    "\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7fd851-e720-4080-bce7-416e45c63955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.307774Z",
     "iopub.status.busy": "2023-07-01T05:55:06.307431Z",
     "iopub.status.idle": "2023-07-01T05:55:06.340166Z",
     "shell.execute_reply": "2023-07-01T05:55:06.339262Z"
    },
    "papermill": {
     "duration": 0.040555,
     "end_time": "2023-07-01T05:55:06.342385",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.301830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = impute.SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(train[input_cols])\n",
    "train[input_cols] = imputer.transform(train[input_cols])\n",
    "test[input_cols] = imputer.transform(test[input_cols])\n",
    "\n",
    "#scaler = preprocessing.MaxAbsScaler()\n",
    "#scaler.fit(train[input_cols])\n",
    "#train[input_cols] = scaler.transform(train[input_cols])\n",
    "#test[input_cols] = scaler.transform(test[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5870a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.353770Z",
     "iopub.status.busy": "2023-07-01T05:55:06.352868Z",
     "iopub.status.idle": "2023-07-01T05:55:06.365137Z",
     "shell.execute_reply": "2023-07-01T05:55:06.364039Z"
    },
    "papermill": {
     "duration": 0.020035,
     "end_time": "2023-07-01T05:55:06.367073",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.347038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "repeated_cv_split = joblib.load(\"../data/iarc-data-split/repeated_5fold_cv_split_4tuning.pkl\")\n",
    "print(len(repeated_cv_split))\n",
    "\n",
    "# number of repetitions to use\n",
    "REPETITIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:05:50.036679Z",
     "iopub.status.busy": "2023-06-09T16:05:50.036272Z",
     "iopub.status.idle": "2023-06-09T16:05:50.061002Z",
     "shell.execute_reply": "2023-06-09T16:05:50.059984Z",
     "shell.execute_reply.started": "2023-06-09T16:05:50.036650Z"
    },
    "papermill": {
     "duration": 0.004372,
     "end_time": "2023-07-01T05:55:06.375986",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.371614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3473651c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.387222Z",
     "iopub.status.busy": "2023-07-01T05:55:06.386117Z",
     "iopub.status.idle": "2023-07-01T05:55:06.392505Z",
     "shell.execute_reply": "2023-07-01T05:55:06.391581Z"
    },
    "papermill": {
     "duration": 0.014034,
     "end_time": "2023-07-01T05:55:06.394493",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.380459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balanced_logloss_(y_pred, y_true):\n",
    "    n0 = np.sum(1-y_true)\n",
    "    n1 = np.sum(y_true)\n",
    "    p1 = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    p0 = 1-p1\n",
    "    log_loss0 = - np.sum((1-y_true) * np.log(p0)) / n0\n",
    "    log_loss1 = - np.sum(y_true * np.log(p1)) / n1\n",
    "    return (log_loss0 + log_loss1)/2\n",
    "\n",
    "#def balanced_logloss(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "#    y_true = data.get_label()\n",
    "#    return 'balanced_logloss', balanced_logloss_(y_pred, y_true), False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d4a43f-6d48-4e04-869d-f8b4387452a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.405019Z",
     "iopub.status.busy": "2023-07-01T05:55:06.404723Z",
     "iopub.status.idle": "2023-07-01T05:55:06.411870Z",
     "shell.execute_reply": "2023-07-01T05:55:06.410749Z"
    },
    "papermill": {
     "duration": 0.01499,
     "end_time": "2023-07-01T05:55:06.413992",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.399002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 4.712962962962963\n",
      "neg_bagging_fraction: 0.21218074656188604\n"
     ]
    }
   ],
   "source": [
    "pct = train.Class.value_counts(normalize=True)\n",
    "scale_pos_weight = pct[0]/pct[1]\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "cnt = train.Class.value_counts(normalize=False)\n",
    "neg_bagging_fraction = cnt[1]/cnt[0]\n",
    "print(\"neg_bagging_fraction:\", neg_bagging_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f39cbdb-9907-4eb4-9937-e797c36f9f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.425182Z",
     "iopub.status.busy": "2023-07-01T05:55:06.424882Z",
     "iopub.status.idle": "2023-07-01T05:55:06.434814Z",
     "shell.execute_reply": "2023-07-01T05:55:06.433950Z"
    },
    "papermill": {
     "duration": 0.017834,
     "end_time": "2023-07-01T05:55:06.436716",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.418882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate(\n",
    "        dataframe,\n",
    "        input_cols, \n",
    "        model_params,\n",
    "        repeated_cv_split,\n",
    "        n_repetitions=REPETITIONS,\n",
    "        verbose=False,\n",
    "        scale_probs=False,\n",
    "    ):\n",
    "\n",
    "    metrics = list()\n",
    "    model_params = dict(model_params)\n",
    "\n",
    "    for repeat in range(n_repetitions):\n",
    "        if verbose:\n",
    "            print(f\"REPEAT NUMBER: {repeat+1}/{n_repetitions}\")\n",
    "        cv_split = repeated_cv_split[f\"repeat_{repeat}\"]\n",
    "        n_folds = len(cv_split)\n",
    "        \n",
    "        for split in cv_split:\n",
    "            fold = split[\"fold\"]\n",
    "            train_idx = split[\"train_idx\"]\n",
    "            valid_idx = split[\"valid_idx\"]\n",
    "            if verbose:\n",
    "                print(f\"training model for fold: {fold+1}/{n_folds}\")\n",
    "        \n",
    "            train_df = dataframe.loc[train_idx,:].reset_index(drop=True)\n",
    "            valid_df = dataframe.loc[valid_idx,:].reset_index(drop=True)\n",
    "\n",
    "            clf = TabPFNClassifier(**model_params)\n",
    "            clf.fit(\n",
    "                train_df[input_cols].values, \n",
    "                train_df[\"Class\"].values, \n",
    "                overwrite_warning=True\n",
    "            )\n",
    "            y_pred = clf.predict_proba(valid_df[input_cols].values)\n",
    "\n",
    "            if scale_probs:\n",
    "                y_pred = (y_pred / np.sum(y_pred, axis=0))\n",
    "                y_pred = (y_pred / np.sum(y_pred, axis=1, keepdims=1))\n",
    "\n",
    "            metrics.append( balanced_logloss_(y_pred[:,1], valid_df[\"Class\"].values) )\n",
    "    \n",
    "    return np.mean(metrics), np.std(metrics)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model_params = dict(\n",
    "        N_ensemble_configurations = 2**trial.suggest_int(\"N_ensemble_configurations_exp\", 2, 7),\n",
    "        no_preprocess_mode = trial.suggest_categorical(\"no_preprocess_mode\", [True, False]),\n",
    "        multiclass_decoder = trial.suggest_categorical(\"multiclass_decoder\", [\"permutation\", \"\"]),\n",
    "        feature_shift_decoder = trial.suggest_categorical(\"feature_shift_decoder\", [True, False]),\n",
    "        scale_probs = trial.suggest_categorical(\"scale_probs\", [True, False]),\n",
    "    )\n",
    "    scale_probs = model_params.pop(\"scale_probs\")\n",
    "    \n",
    "    metric_mean, metric_std = train_validate(\n",
    "        dataframe = train,\n",
    "        input_cols = input_cols,\n",
    "        model_params = model_params,\n",
    "        repeated_cv_split = repeated_cv_split,\n",
    "        n_repetitions = REPETITIONS,\n",
    "        verbose = False,\n",
    "        scale_probs = scale_probs,\n",
    "    )\n",
    "    \n",
    "    return metric_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1ce92b-0991-4967-8f51-f27d31fbcfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T05:55:06.447634Z",
     "iopub.status.busy": "2023-07-01T05:55:06.447325Z",
     "iopub.status.idle": "2023-07-01T05:56:19.458944Z",
     "shell.execute_reply": "2023-07-01T05:56:19.458008Z"
    },
    "papermill": {
     "duration": 73.019318,
     "end_time": "2023-07-01T05:56:19.460774",
     "exception": false,
     "start_time": "2023-07-01T05:55:06.441456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 2.68 s, total: 3min 22s\n",
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2655965460010707, 0.08868033645292092)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_validate(\n",
    "    dataframe = train,\n",
    "    input_cols = input_cols,\n",
    "    model_params = dict(N_ensemble_configurations=4, ),\n",
    "    repeated_cv_split = repeated_cv_split,\n",
    "    n_repetitions = REPETITIONS,\n",
    "    verbose = False,\n",
    "    scale_probs = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea38970c-522c-4506-9ed8-a0b04401593c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-01T05:56:19.482113Z",
     "iopub.status.busy": "2023-07-01T05:56:19.481752Z",
     "iopub.status.idle": "2023-07-01T13:04:08.554833Z",
     "shell.execute_reply": "2023-07-01T13:04:08.553935Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 25669.085874,
     "end_time": "2023-07-01T13:04:08.556864",
     "exception": false,
     "start_time": "2023-07-01T05:56:19.470990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 05:56:19,674] Using an existing study with name 'iarc-tabpfn' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:11:23,949] Trial 1 finished with value: 0.29698059997668513 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 1 with value: 0.29698059997668513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:12:15,010] Trial 2 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 1 with value: 0.29698059997668513.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:12:41,135] Trial 3 finished with value: 0.296654374432833 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 3 with value: 0.296654374432833.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:16:10,548] Trial 4 finished with value: 0.4173106653104265 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 3 with value: 0.296654374432833.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:17:57,788] Trial 5 finished with value: 0.39316987343286286 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 3 with value: 0.296654374432833.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:18:48,209] Trial 6 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:19:14,549] Trial 7 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:20:49,869] Trial 8 finished with value: 0.30035139091130053 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:24:34,883] Trial 9 finished with value: 0.3937472782309041 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:32:10,613] Trial 10 finished with value: 0.2971904048926236 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:32:46,032] Trial 11 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:33:12,384] Trial 12 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:34:21,592] Trial 13 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 6 with value: 0.266102183644723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:35:31,167] Trial 14 finished with value: 0.2655965460010707 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:36:06,618] Trial 15 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:37:00,668] Trial 16 finished with value: 0.41554067067923595 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:37:51,652] Trial 17 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:38:27,815] Trial 18 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:46:18,642] Trial 19 finished with value: 0.39404615658826847 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:46:54,383] Trial 20 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 14 with value: 0.2655965460010707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 06:48:03,447] Trial 21 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:00:05,359] Trial 22 finished with value: 0.2989522041717339 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:00:55,830] Trial 23 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:01:22,258] Trial 24 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:01:48,627] Trial 25 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:09:14,839] Trial 26 finished with value: 0.2694428515510576 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:10:05,719] Trial 27 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:17:15,979] Trial 28 finished with value: 0.4176273433624998 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:18:28,922] Trial 29 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:19:05,228] Trial 30 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:20:15,712] Trial 31 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:20:41,689] Trial 32 finished with value: 0.296654374432833 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:27:55,033] Trial 33 finished with value: 0.2988060704435798 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:29:04,310] Trial 34 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:29:40,115] Trial 35 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:30:49,313] Trial 36 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:31:43,493] Trial 37 finished with value: 0.2978977439139101 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:32:33,904] Trial 38 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:35:42,583] Trial 39 finished with value: 0.270388946699384 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:36:51,713] Trial 40 finished with value: 0.394878742113767 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 07:48:56,537] Trial 41 finished with value: 0.2989522041717339 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:03:17,953] Trial 42 finished with value: 0.39208342544076025 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:03:45,412] Trial 43 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:04:21,595] Trial 44 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:32:20,739] Trial 45 finished with value: 0.2665660189038611 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:33:30,004] Trial 46 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:34:25,024] Trial 47 finished with value: 0.2990342687735702 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:35:01,212] Trial 48 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:35:38,491] Trial 49 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:36:47,999] Trial 50 finished with value: 0.3698314201341355 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:37:57,846] Trial 51 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:52:13,603] Trial 52 finished with value: 0.37935349297146453 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:53:46,156] Trial 53 finished with value: 0.2961169036577141 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:54:36,762] Trial 54 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:57:46,485] Trial 55 finished with value: 0.37647782711514766 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 08:58:37,308] Trial 56 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:21:53,248] Trial 57 finished with value: 0.41750128810886017 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:23:26,090] Trial 58 finished with value: 0.4146821036200878 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:30:39,400] Trial 59 finished with value: 0.4279995390485511 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:42:48,034] Trial 60 finished with value: 0.4280210569905654 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:43:25,397] Trial 61 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:50:54,601] Trial 62 finished with value: 0.3787657670406087 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 09:52:42,021] Trial 63 finished with value: 0.26793315380962723 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 10:16:09,608] Trial 64 finished with value: 0.39225560472847454 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 10:17:00,521] Trial 65 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 10:31:03,285] Trial 66 finished with value: 0.41771174567248914 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 10:45:21,971] Trial 67 finished with value: 0.2666139366548366 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 10:48:16,825] Trial 68 finished with value: 0.29931616096650493 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:02:35,531] Trial 69 finished with value: 0.26884449311357017 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:03:01,770] Trial 70 finished with value: 0.296654374432833 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:03:28,422] Trial 71 finished with value: 0.296654374432833 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:30:58,640] Trial 72 finished with value: 0.3799949526200402 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:32:08,061] Trial 73 finished with value: 0.26934247153773794 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:33:55,662] Trial 74 finished with value: 0.3737367361197029 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:34:31,436] Trial 75 finished with value: 0.41871202892380305 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:41:56,779] Trial 76 finished with value: 0.2667171219952928 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:43:44,442] Trial 77 finished with value: 0.2665898008855305 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:46:42,852] Trial 78 finished with value: 0.43034652334778883 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:58:52,976] Trial 79 finished with value: 0.4280210569905654 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 11:59:19,386] Trial 80 finished with value: 0.296654374432833 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:00:11,624] Trial 81 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:01:21,095] Trial 82 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 5, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:02:15,705] Trial 83 finished with value: 0.42677676317878893 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:26:13,986] Trial 84 finished with value: 0.26906110008176876 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:27:05,996] Trial 85 finished with value: 0.266102183644723 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:28:17,191] Trial 86 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:29:28,221] Trial 87 finished with value: 0.2646769922995128 and parameters: {'N_ensemble_configurations_exp': 2, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:30:39,044] Trial 88 finished with value: 0.3793299562464483 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:31:16,836] Trial 89 finished with value: 0.29665182398207596 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:31:43,908] Trial 90 finished with value: 0.42738769622145967 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:55:22,996] Trial 91 finished with value: 0.2972523641747772 and parameters: {'N_ensemble_configurations_exp': 7, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 12:56:58,806] Trial 92 finished with value: 0.42856823184568027 and parameters: {'N_ensemble_configurations_exp': 3, 'feature_shift_decoder': True, 'multiclass_decoder': '', 'no_preprocess_mode': True, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 13:00:00,194] Trial 93 finished with value: 0.296726682313197 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': True, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 13:03:16,301] Trial 94 finished with value: 0.2661235692600299 and parameters: {'N_ensemble_configurations_exp': 4, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation', 'no_preprocess_mode': False, 'scale_probs': True}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-01 13:04:08,371] Trial 95 finished with value: 0.3917667228135668 and parameters: {'N_ensemble_configurations_exp': 6, 'feature_shift_decoder': False, 'multiclass_decoder': '', 'no_preprocess_mode': False, 'scale_probs': False}. Best is trial 21 with value: 0.2646769922995128.\n"
     ]
    }
   ],
   "source": [
    "do_optimize = True\n",
    "\n",
    "search_space = {\n",
    "    'N_ensemble_configurations_exp': [2,3,4,5,6,7],\n",
    "    'no_preprocess_mode': [True, False],\n",
    "    \"multiclass_decoder\": [\"permutation\", \"\"],\n",
    "    \"feature_shift_decoder\": [True, False],\n",
    "    \"scale_probs\": [True, False],\n",
    "}\n",
    "study = optuna.create_study(\n",
    "    study_name=\"iarc-tabpfn\",\n",
    "    direction='minimize',\n",
    "    storage='sqlite:///iarc-tabpfn.db',\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.GridSampler(search_space),\n",
    ")\n",
    "\n",
    "if do_optimize:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=10_000, \n",
    "        timeout=43200, # 12 hours\n",
    "        n_jobs=1, \n",
    "        gc_after_trial=True,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af4fee2-c3d4-4e1a-9854-d5a74865e060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:09.565844Z",
     "iopub.status.busy": "2023-07-01T13:04:09.565454Z",
     "iopub.status.idle": "2023-07-01T13:04:09.637451Z",
     "shell.execute_reply": "2023-07-01T13:04:09.636207Z"
    },
    "papermill": {
     "duration": 0.577621,
     "end_time": "2023-07-01T13:04:09.639893",
     "exception": false,
     "start_time": "2023-07-01T13:04:09.062272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_N_ensemble_configurations_exp</th>\n",
       "      <th>params_feature_shift_decoder</th>\n",
       "      <th>params_multiclass_decoder</th>\n",
       "      <th>params_no_preprocess_mode</th>\n",
       "      <th>params_scale_probs</th>\n",
       "      <th>system_attrs_grid_id</th>\n",
       "      <th>system_attrs_search_space</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 07:19:05.409987</td>\n",
       "      <td>2023-07-01 07:20:15.692573</td>\n",
       "      <td>0 days 00:01:10.282586</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 07:17:16.166755</td>\n",
       "      <td>2023-07-01 07:18:28.903713</td>\n",
       "      <td>0 days 00:01:12.736958</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 12:28:17.376087</td>\n",
       "      <td>2023-07-01 12:29:28.202828</td>\n",
       "      <td>0 days 00:01:10.826741</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 12:27:06.189086</td>\n",
       "      <td>2023-07-01 12:28:17.171292</td>\n",
       "      <td>0 days 00:01:10.982206</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>90</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 06:46:54.560737</td>\n",
       "      <td>2023-07-01 06:48:03.427670</td>\n",
       "      <td>0 days 00:01:08.866933</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>2023-07-01 07:29:40.289611</td>\n",
       "      <td>2023-07-01 07:30:49.294919</td>\n",
       "      <td>0 days 00:01:09.005308</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.265597</td>\n",
       "      <td>2023-07-01 06:34:21.762442</td>\n",
       "      <td>2023-07-01 06:35:31.148169</td>\n",
       "      <td>0 days 00:01:09.385727</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 10:16:09.796625</td>\n",
       "      <td>2023-07-01 10:17:00.501528</td>\n",
       "      <td>0 days 00:00:50.704903</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 08:53:46.336089</td>\n",
       "      <td>2023-07-01 08:54:36.742089</td>\n",
       "      <td>0 days 00:00:50.406000</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>94</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 07:00:05.536160</td>\n",
       "      <td>2023-07-01 07:00:55.810534</td>\n",
       "      <td>0 days 00:00:50.274374</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 07:31:43.673539</td>\n",
       "      <td>2023-07-01 07:32:33.885041</td>\n",
       "      <td>0 days 00:00:50.211502</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 12:26:14.179767</td>\n",
       "      <td>2023-07-01 12:27:05.976813</td>\n",
       "      <td>0 days 00:00:51.797046</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>2023-07-01 06:17:57.983326</td>\n",
       "      <td>2023-07-01 06:18:48.191173</td>\n",
       "      <td>0 days 00:00:50.207847</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.266124</td>\n",
       "      <td>2023-07-01 13:00:00.386416</td>\n",
       "      <td>2023-07-01 13:03:16.280740</td>\n",
       "      <td>0 days 00:03:15.894324</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.266566</td>\n",
       "      <td>2023-07-01 08:04:21.761067</td>\n",
       "      <td>2023-07-01 08:32:20.720128</td>\n",
       "      <td>0 days 00:27:58.959061</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>82</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>0.266590</td>\n",
       "      <td>2023-07-01 11:41:56.958981</td>\n",
       "      <td>2023-07-01 11:43:44.424279</td>\n",
       "      <td>0 days 00:01:47.465298</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.266614</td>\n",
       "      <td>2023-07-01 10:31:03.478662</td>\n",
       "      <td>2023-07-01 10:45:21.952651</td>\n",
       "      <td>0 days 00:14:18.473989</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>66</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>0.266717</td>\n",
       "      <td>2023-07-01 11:34:31.605338</td>\n",
       "      <td>2023-07-01 11:41:56.760753</td>\n",
       "      <td>0 days 00:07:25.155415</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.267933</td>\n",
       "      <td>2023-07-01 09:50:54.781359</td>\n",
       "      <td>2023-07-01 09:52:42.002282</td>\n",
       "      <td>0 days 00:01:47.220923</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>0.268844</td>\n",
       "      <td>2023-07-01 10:48:17.008875</td>\n",
       "      <td>2023-07-01 11:02:35.511600</td>\n",
       "      <td>0 days 00:14:18.502725</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>70</td>\n",
       "      <td>{'N_ensemble_configurations_exp': [2, 3, 4, 5,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "31      31  0.264677 2023-07-01 07:19:05.409987 2023-07-01 07:20:15.692573   \n",
       "29      29  0.264677 2023-07-01 07:17:16.166755 2023-07-01 07:18:28.903713   \n",
       "87      87  0.264677 2023-07-01 12:28:17.376087 2023-07-01 12:29:28.202828   \n",
       "86      86  0.264677 2023-07-01 12:27:06.189086 2023-07-01 12:28:17.171292   \n",
       "21      21  0.264677 2023-07-01 06:46:54.560737 2023-07-01 06:48:03.427670   \n",
       "36      36  0.264677 2023-07-01 07:29:40.289611 2023-07-01 07:30:49.294919   \n",
       "14      14  0.265597 2023-07-01 06:34:21.762442 2023-07-01 06:35:31.148169   \n",
       "65      65  0.266102 2023-07-01 10:16:09.796625 2023-07-01 10:17:00.501528   \n",
       "54      54  0.266102 2023-07-01 08:53:46.336089 2023-07-01 08:54:36.742089   \n",
       "23      23  0.266102 2023-07-01 07:00:05.536160 2023-07-01 07:00:55.810534   \n",
       "38      38  0.266102 2023-07-01 07:31:43.673539 2023-07-01 07:32:33.885041   \n",
       "85      85  0.266102 2023-07-01 12:26:14.179767 2023-07-01 12:27:05.976813   \n",
       "6        6  0.266102 2023-07-01 06:17:57.983326 2023-07-01 06:18:48.191173   \n",
       "94      94  0.266124 2023-07-01 13:00:00.386416 2023-07-01 13:03:16.280740   \n",
       "45      45  0.266566 2023-07-01 08:04:21.761067 2023-07-01 08:32:20.720128   \n",
       "77      77  0.266590 2023-07-01 11:41:56.958981 2023-07-01 11:43:44.424279   \n",
       "67      67  0.266614 2023-07-01 10:31:03.478662 2023-07-01 10:45:21.952651   \n",
       "76      76  0.266717 2023-07-01 11:34:31.605338 2023-07-01 11:41:56.760753   \n",
       "63      63  0.267933 2023-07-01 09:50:54.781359 2023-07-01 09:52:42.002282   \n",
       "69      69  0.268844 2023-07-01 10:48:17.008875 2023-07-01 11:02:35.511600   \n",
       "\n",
       "                 duration  params_N_ensemble_configurations_exp  \\\n",
       "31 0 days 00:01:10.282586                                     5   \n",
       "29 0 days 00:01:12.736958                                     4   \n",
       "87 0 days 00:01:10.826741                                     2   \n",
       "86 0 days 00:01:10.982206                                     7   \n",
       "21 0 days 00:01:08.866933                                     3   \n",
       "36 0 days 00:01:09.005308                                     6   \n",
       "14 0 days 00:01:09.385727                                     2   \n",
       "65 0 days 00:00:50.704903                                     4   \n",
       "54 0 days 00:00:50.406000                                     7   \n",
       "23 0 days 00:00:50.274374                                     2   \n",
       "38 0 days 00:00:50.211502                                     3   \n",
       "85 0 days 00:00:51.797046                                     6   \n",
       "6  0 days 00:00:50.207847                                     5   \n",
       "94 0 days 00:03:15.894324                                     4   \n",
       "45 0 days 00:27:58.959061                                     7   \n",
       "77 0 days 00:01:47.465298                                     3   \n",
       "67 0 days 00:14:18.473989                                     6   \n",
       "76 0 days 00:07:25.155415                                     5   \n",
       "63 0 days 00:01:47.220923                                     3   \n",
       "69 0 days 00:14:18.502725                                     6   \n",
       "\n",
       "    params_feature_shift_decoder params_multiclass_decoder  \\\n",
       "31                         False               permutation   \n",
       "29                         False               permutation   \n",
       "87                         False               permutation   \n",
       "86                         False               permutation   \n",
       "21                         False               permutation   \n",
       "36                         False               permutation   \n",
       "14                          True               permutation   \n",
       "65                         False                             \n",
       "54                         False                             \n",
       "23                         False                             \n",
       "38                         False                             \n",
       "85                         False                             \n",
       "6                          False                             \n",
       "94                          True               permutation   \n",
       "45                          True               permutation   \n",
       "77                          True               permutation   \n",
       "67                          True               permutation   \n",
       "76                          True               permutation   \n",
       "63                          True                             \n",
       "69                          True                             \n",
       "\n",
       "    params_no_preprocess_mode  params_scale_probs  system_attrs_grid_id  \\\n",
       "31                      False                True                    58   \n",
       "29                      False                True                    42   \n",
       "87                      False                True                    10   \n",
       "86                      False                True                    90   \n",
       "21                      False                True                    26   \n",
       "36                      False                True                    74   \n",
       "14                      False                True                     2   \n",
       "65                      False                True                    46   \n",
       "54                      False                True                    94   \n",
       "23                      False                True                    14   \n",
       "38                      False                True                    30   \n",
       "85                      False                True                    78   \n",
       "6                       False                True                    62   \n",
       "94                      False                True                    34   \n",
       "45                      False                True                    82   \n",
       "77                      False                True                    18   \n",
       "67                      False                True                    66   \n",
       "76                      False                True                    50   \n",
       "63                      False                True                    22   \n",
       "69                      False                True                    70   \n",
       "\n",
       "                            system_attrs_search_space     state  \n",
       "31  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "29  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "87  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "86  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "21  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "36  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "14  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "65  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "54  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "23  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "38  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "85  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "6   {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "94  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "45  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "77  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "67  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "76  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "63  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  \n",
       "69  {'N_ensemble_configurations_exp': [2, 3, 4, 5,...  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318b0518-c689-4f08-b0cd-158e9087ae60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:10.762858Z",
     "iopub.status.busy": "2023-07-01T13:04:10.762095Z",
     "iopub.status.idle": "2023-07-01T13:04:11.862633Z",
     "shell.execute_reply": "2023-07-01T13:04:11.861667Z"
    },
    "papermill": {
     "duration": 1.607445,
     "end_time": "2023-07-01T13:04:11.864553",
     "exception": false,
     "start_time": "2023-07-01T13:04:10.257108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavillan/mambaforge/envs/kg/lib/python3.10/site-packages/kaleido/scopes/base.py:188: DeprecationWarning:\n",
      "\n",
      "setDaemon() is deprecated, set the daemon attribute instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf396a79-1638-45ba-b2f1-ace3c310260b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:12.867506Z",
     "iopub.status.busy": "2023-07-01T13:04:12.867113Z",
     "iopub.status.idle": "2023-07-01T13:04:13.855670Z",
     "shell.execute_reply": "2023-07-01T13:04:13.854825Z"
    },
    "papermill": {
     "duration": 1.495178,
     "end_time": "2023-07-01T13:04:13.857707",
     "exception": false,
     "start_time": "2023-07-01T13:04:12.362529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd2e02a-b799-4e04-9448-5a36a213efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:14.970592Z",
     "iopub.status.busy": "2023-07-01T13:04:14.969623Z",
     "iopub.status.idle": "2023-07-01T13:04:15.412273Z",
     "shell.execute_reply": "2023-07-01T13:04:15.411365Z"
    },
    "papermill": {
     "duration": 1.058674,
     "end_time": "2023-07-01T13:04:15.414275",
     "exception": false,
     "start_time": "2023-07-01T13:04:14.355601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0890fba3-07cb-4889-9387-fcd4e3dbb884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:16.420152Z",
     "iopub.status.busy": "2023-07-01T13:04:16.419717Z",
     "iopub.status.idle": "2023-07-01T13:04:16.502232Z",
     "shell.execute_reply": "2023-07-01T13:04:16.501366Z"
    },
    "papermill": {
     "duration": 0.585555,
     "end_time": "2023-07-01T13:04:16.504191",
     "exception": false,
     "start_time": "2023-07-01T13:04:15.918636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a0f23b-e67e-4af1-b8aa-f25fd6b3519e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:17.614534Z",
     "iopub.status.busy": "2023-07-01T13:04:17.614123Z",
     "iopub.status.idle": "2023-07-01T13:04:19.519562Z",
     "shell.execute_reply": "2023-07-01T13:04:19.518769Z"
    },
    "papermill": {
     "duration": 2.516013,
     "end_time": "2023-07-01T13:04:19.521390",
     "exception": false,
     "start_time": "2023-07-01T13:04:17.005377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa53e62-a488-4f7e-99fa-c3d6c7b6689b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T13:04:20.529643Z",
     "iopub.status.busy": "2023-07-01T13:04:20.529283Z",
     "iopub.status.idle": "2023-07-01T13:04:20.543825Z",
     "shell.execute_reply": "2023-07-01T13:04:20.542822Z"
    },
    "papermill": {
     "duration": 0.516212,
     "end_time": "2023-07-01T13:04:20.545810",
     "exception": false,
     "start_time": "2023-07-01T13:04:20.029598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_shift_decoder': False,\n",
       " 'multiclass_decoder': 'permutation',\n",
       " 'no_preprocess_mode': False,\n",
       " 'scale_probs': True,\n",
       " 'N_ensemble_configurations': 8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = dict(study.best_params)\n",
    "best_params[\"N_ensemble_configurations\"] = 2**best_params.pop(\"N_ensemble_configurations_exp\")\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6e7fd",
   "metadata": {
    "papermill": {
     "duration": 0.499368,
     "end_time": "2023-07-01T13:04:21.553991",
     "exception": false,
     "start_time": "2023-07-01T13:04:21.054623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25763.664364,
   "end_time": "2023-07-01T13:04:24.813900",
   "environment_variables": {},
   "exception": null,
   "input_path": "tuning/iarc-tabpfn.ipynb",
   "output_path": "tuning/outputs/iarc-tabpfn.ipynb",
   "parameters": {},
   "start_time": "2023-07-01T05:55:01.149536",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

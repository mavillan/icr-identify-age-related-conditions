{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791e4da7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:45.823193Z",
     "iopub.status.busy": "2023-08-08T22:45:45.822677Z",
     "iopub.status.idle": "2023-08-08T22:45:49.086197Z",
     "shell.execute_reply": "2023-08-08T22:45:49.085456Z"
    },
    "papermill": {
     "duration": 3.271048,
     "end_time": "2023-08-08T22:45:49.088488",
     "exception": false,
     "start_time": "2023-08-08T22:45:45.817440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavillan/mambaforge/envs/kg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_contour\n",
    "    , plot_edf\n",
    "    , plot_intermediate_values\n",
    "    , plot_optimization_history\n",
    "    , plot_parallel_coordinate\n",
    "    , plot_param_importances\n",
    "    , plot_slice\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b684f",
   "metadata": {
    "papermill": {
     "duration": 0.003051,
     "end_time": "2023-08-08T22:45:49.094935",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.091884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783b3296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.102699Z",
     "iopub.status.busy": "2023-08-08T22:45:49.101901Z",
     "iopub.status.idle": "2023-08-08T22:45:49.192617Z",
     "shell.execute_reply": "2023-08-08T22:45:49.191831Z"
    },
    "papermill": {
     "duration": 0.09687,
     "end_time": "2023-08-08T22:45:49.194615",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.097745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>BZ</th>\n",
       "      <th>CB</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CF</th>\n",
       "      <th>CH</th>\n",
       "      <th>CL</th>\n",
       "      <th>CR</th>\n",
       "      <th>CS</th>\n",
       "      <th>CU</th>\n",
       "      <th>CW</th>\n",
       "      <th>DA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DF</th>\n",
       "      <th>DH</th>\n",
       "      <th>DI</th>\n",
       "      <th>DL</th>\n",
       "      <th>DN</th>\n",
       "      <th>DU</th>\n",
       "      <th>DV</th>\n",
       "      <th>DY</th>\n",
       "      <th>EB</th>\n",
       "      <th>EE</th>\n",
       "      <th>EG</th>\n",
       "      <th>EH</th>\n",
       "      <th>EJ</th>\n",
       "      <th>EL</th>\n",
       "      <th>EP</th>\n",
       "      <th>EU</th>\n",
       "      <th>FC</th>\n",
       "      <th>FD</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "      <th>Alpha_A</th>\n",
       "      <th>Alpha_B</th>\n",
       "      <th>Alpha_D</th>\n",
       "      <th>Alpha_G</th>\n",
       "      <th>Beta_A</th>\n",
       "      <th>Beta_B</th>\n",
       "      <th>Beta_C</th>\n",
       "      <th>Gamma_A</th>\n",
       "      <th>Gamma_B</th>\n",
       "      <th>Gamma_E</th>\n",
       "      <th>Gamma_F</th>\n",
       "      <th>Gamma_G</th>\n",
       "      <th>Gamma_H</th>\n",
       "      <th>Gamma_M</th>\n",
       "      <th>Gamma_N</th>\n",
       "      <th>Delta_A</th>\n",
       "      <th>Delta_B</th>\n",
       "      <th>Delta_C</th>\n",
       "      <th>Delta_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>175.638726</td>\n",
       "      <td>152.707705</td>\n",
       "      <td>823.928241</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>47.223358</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>23.387600</td>\n",
       "      <td>4.851915</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>13.784111</td>\n",
       "      <td>1.302012</td>\n",
       "      <td>36.205956</td>\n",
       "      <td>69.08340</td>\n",
       "      <td>295.570575</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>89.245560</td>\n",
       "      <td>84.31664</td>\n",
       "      <td>29.657104</td>\n",
       "      <td>5.310690</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>23.187704</td>\n",
       "      <td>7.294176</td>\n",
       "      <td>1.987283</td>\n",
       "      <td>1433.166750</td>\n",
       "      <td>0.949104</td>\n",
       "      <td>1</td>\n",
       "      <td>30.879420</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>13.394640</td>\n",
       "      <td>10.265073</td>\n",
       "      <td>9028.291921</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>155.868030</td>\n",
       "      <td>14.754720</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>0.484710</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.117800</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>178.553100</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>37.532000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>1111.287150</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>52.260480</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>219.320160</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>70.81970</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>11.050410</td>\n",
       "      <td>661.518640</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>88.159360</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>41.116960</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>139.824570</td>\n",
       "      <td>71.57120</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>7.386060</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>15691.552180</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>1</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>10965.766040</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>24.0108</td>\n",
       "      <td>324.546318</td>\n",
       "      <td>149.717165</td>\n",
       "      <td>6074.859475</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>82.213495</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>72.644264</td>\n",
       "      <td>30.537722</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>31.724726</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>34.415360</td>\n",
       "      <td>74.06532</td>\n",
       "      <td>200.178160</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>97.920120</td>\n",
       "      <td>52.83888</td>\n",
       "      <td>26.019912</td>\n",
       "      <td>1.144902</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>9.064856</td>\n",
       "      <td>7.350720</td>\n",
       "      <td>3.490846</td>\n",
       "      <td>1403.656300</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>91.994825</td>\n",
       "      <td>51.141336</td>\n",
       "      <td>29.102640</td>\n",
       "      <td>4.274640</td>\n",
       "      <td>16198.049590</td>\n",
       "      <td>13.666727</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>fd3dafe738fd</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>3130.05946</td>\n",
       "      <td>123.763599</td>\n",
       "      <td>9.513984</td>\n",
       "      <td>13.020852</td>\n",
       "      <td>3.499305</td>\n",
       "      <td>0.077343</td>\n",
       "      <td>8.545512</td>\n",
       "      <td>2.804172</td>\n",
       "      <td>4157.68439</td>\n",
       "      <td>21.1860</td>\n",
       "      <td>167.877117</td>\n",
       "      <td>27.287375</td>\n",
       "      <td>365.516874</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>41.368691</td>\n",
       "      <td>0.691257</td>\n",
       "      <td>55.163024</td>\n",
       "      <td>4.780452</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>1.177525</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>40.159779</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>7.030640</td>\n",
       "      <td>21.75904</td>\n",
       "      <td>355.930925</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.445479</td>\n",
       "      <td>176.977590</td>\n",
       "      <td>90.91832</td>\n",
       "      <td>27.957928</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>2.41906</td>\n",
       "      <td>32.508604</td>\n",
       "      <td>8.015112</td>\n",
       "      <td>1.354416</td>\n",
       "      <td>495.086300</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>51.618996</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>65.821872</td>\n",
       "      <td>29.708112</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>17167.209610</td>\n",
       "      <td>9.879296</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.26092</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>8.967128</td>\n",
       "      <td>217.148554</td>\n",
       "      <td>8095.932828</td>\n",
       "      <td>24.640462</td>\n",
       "      <td>69.191944</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>fd895603f071</td>\n",
       "      <td>0.435846</td>\n",
       "      <td>5462.03438</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>46.551007</td>\n",
       "      <td>15.973224</td>\n",
       "      <td>5.979825</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>12.622906</td>\n",
       "      <td>3.777550</td>\n",
       "      <td>5654.07556</td>\n",
       "      <td>27.1887</td>\n",
       "      <td>285.628059</td>\n",
       "      <td>344.644105</td>\n",
       "      <td>505.006814</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>61.910576</td>\n",
       "      <td>0.772304</td>\n",
       "      <td>85.233928</td>\n",
       "      <td>6.682597</td>\n",
       "      <td>0.038208</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.761025</td>\n",
       "      <td>39.852923</td>\n",
       "      <td>2.146113</td>\n",
       "      <td>33.648356</td>\n",
       "      <td>43.90996</td>\n",
       "      <td>157.393715</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.437280</td>\n",
       "      <td>192.598575</td>\n",
       "      <td>123.17624</td>\n",
       "      <td>26.750080</td>\n",
       "      <td>0.648318</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>18.197092</td>\n",
       "      <td>8.976360</td>\n",
       "      <td>0.753797</td>\n",
       "      <td>1722.674025</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>1</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>114.801199</td>\n",
       "      <td>447.657600</td>\n",
       "      <td>69.343680</td>\n",
       "      <td>6.067614</td>\n",
       "      <td>18460.330020</td>\n",
       "      <td>10.910227</td>\n",
       "      <td>10.223150</td>\n",
       "      <td>1.24236</td>\n",
       "      <td>0.426699</td>\n",
       "      <td>35.896418</td>\n",
       "      <td>496.994214</td>\n",
       "      <td>3085.308063</td>\n",
       "      <td>29.648928</td>\n",
       "      <td>124.808872</td>\n",
       "      <td>0.145340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>fd8ef6377f76</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>2459.10720</td>\n",
       "      <td>130.138587</td>\n",
       "      <td>55.355778</td>\n",
       "      <td>10.005552</td>\n",
       "      <td>8.070549</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>15.408390</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5888.87769</td>\n",
       "      <td>20.4798</td>\n",
       "      <td>178.661133</td>\n",
       "      <td>103.988995</td>\n",
       "      <td>2083.880500</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>90.411867</td>\n",
       "      <td>0.708616</td>\n",
       "      <td>142.680216</td>\n",
       "      <td>7.809288</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>1.495775</td>\n",
       "      <td>0.879825</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.489590</td>\n",
       "      <td>36.807176</td>\n",
       "      <td>104.62032</td>\n",
       "      <td>223.209115</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.382620</td>\n",
       "      <td>218.915925</td>\n",
       "      <td>326.23620</td>\n",
       "      <td>26.463472</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>47.552312</td>\n",
       "      <td>9.478188</td>\n",
       "      <td>2.225112</td>\n",
       "      <td>2565.402825</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>87.397401</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>71.725584</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>5088.922912</td>\n",
       "      <td>12.029366</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>19.962092</td>\n",
       "      <td>128.896894</td>\n",
       "      <td>6474.652866</td>\n",
       "      <td>26.166072</td>\n",
       "      <td>119.559420</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>fe1942975e40</td>\n",
       "      <td>0.363205</td>\n",
       "      <td>1263.53524</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>23.685856</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>7.981959</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>7.524588</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4517.86560</td>\n",
       "      <td>19.0674</td>\n",
       "      <td>119.162529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722.377629</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>12.499760</td>\n",
       "      <td>0.602254</td>\n",
       "      <td>122.939496</td>\n",
       "      <td>2.964975</td>\n",
       "      <td>0.022288</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.583125</td>\n",
       "      <td>34.367872</td>\n",
       "      <td>1.428903</td>\n",
       "      <td>36.699352</td>\n",
       "      <td>51.04140</td>\n",
       "      <td>112.196630</td>\n",
       "      <td>0.532818</td>\n",
       "      <td>0.549333</td>\n",
       "      <td>113.526045</td>\n",
       "      <td>96.97092</td>\n",
       "      <td>27.104928</td>\n",
       "      <td>0.510378</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>38.271840</td>\n",
       "      <td>10.078968</td>\n",
       "      <td>1.628524</td>\n",
       "      <td>1318.962875</td>\n",
       "      <td>0.139932</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.706633</td>\n",
       "      <td>8.259384</td>\n",
       "      <td>38.133312</td>\n",
       "      <td>6.192291</td>\n",
       "      <td>6464.250832</td>\n",
       "      <td>8.026928</td>\n",
       "      <td>9.256996</td>\n",
       "      <td>0.78764</td>\n",
       "      <td>0.670527</td>\n",
       "      <td>24.594488</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>1965.343176</td>\n",
       "      <td>25.116750</td>\n",
       "      <td>37.155112</td>\n",
       "      <td>0.184622</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ffcca4ded3bb</td>\n",
       "      <td>0.482849</td>\n",
       "      <td>2672.53426</td>\n",
       "      <td>546.663930</td>\n",
       "      <td>112.006102</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.198099</td>\n",
       "      <td>0.116928</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>7.948668</td>\n",
       "      <td>2818.01707</td>\n",
       "      <td>21.1860</td>\n",
       "      <td>306.127863</td>\n",
       "      <td>6.090490</td>\n",
       "      <td>747.474930</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>67.222974</td>\n",
       "      <td>0.644837</td>\n",
       "      <td>271.240664</td>\n",
       "      <td>10.479286</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>1.241175</td>\n",
       "      <td>2.404275</td>\n",
       "      <td>42.799438</td>\n",
       "      <td>0.915822</td>\n",
       "      <td>37.824144</td>\n",
       "      <td>35.72704</td>\n",
       "      <td>889.496905</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.172179</td>\n",
       "      <td>156.345390</td>\n",
       "      <td>82.54008</td>\n",
       "      <td>21.086160</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>24.499368</td>\n",
       "      <td>7.873752</td>\n",
       "      <td>2.374259</td>\n",
       "      <td>912.311525</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0</td>\n",
       "      <td>15.960087</td>\n",
       "      <td>181.218219</td>\n",
       "      <td>78.370464</td>\n",
       "      <td>66.893232</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>5895.352262</td>\n",
       "      <td>7.745765</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>1.14492</td>\n",
       "      <td>0.149006</td>\n",
       "      <td>13.673940</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>6850.484442</td>\n",
       "      <td>45.745974</td>\n",
       "      <td>114.842372</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id        AB          AF          AH          AM         AR  \\\n",
       "0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688   \n",
       "1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n",
       "2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n",
       "3    043ac50845d5  0.252107  3819.65177  120.201618   77.112203   8.138688   \n",
       "4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n",
       "..            ...       ...         ...         ...         ...        ...   \n",
       "612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n",
       "613  fd895603f071  0.435846  5462.03438   85.200147   46.551007  15.973224   \n",
       "614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n",
       "615  fe1942975e40  0.363205  1263.53524   85.200147   23.685856   8.138688   \n",
       "616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n",
       "\n",
       "           AX        AY         AZ          BC          BD       BN  \\\n",
       "0    0.699861  0.025578   9.812214    5.555634  4126.58731  22.5984   \n",
       "1    3.632190  0.025578  13.517790    1.229900  5496.92824  19.4205   \n",
       "2    6.732840  0.025578  12.824570    1.229900  5135.78024  26.4825   \n",
       "3    3.685344  0.025578  11.053708    1.229900  4169.67738  23.6577   \n",
       "4    3.942255  0.054810   3.396778  102.151980  5728.73412  24.0108   \n",
       "..        ...       ...        ...         ...         ...      ...   \n",
       "612  3.499305  0.077343   8.545512    2.804172  4157.68439  21.1860   \n",
       "613  5.979825  0.025882  12.622906    3.777550  5654.07556  27.1887   \n",
       "614  8.070549  0.025578  15.408390    1.229900  5888.87769  20.4798   \n",
       "615  7.981959  0.025578   7.524588    1.229900  4517.86560  19.0674   \n",
       "616  3.198099  0.116928   3.396778    7.948668  2818.01707  21.1860   \n",
       "\n",
       "             BP          BQ           BR          BZ         CB        CC  \\\n",
       "0    175.638726  152.707705   823.928241  257.432377  47.223358  0.563481   \n",
       "1    155.868030   14.754720    51.216883  257.432377  30.284345  0.484710   \n",
       "2    128.988531  219.320160   482.141594  257.432377  32.563713  0.495852   \n",
       "3    237.282264   11.050410   661.518640  257.432377  15.201914  0.717882   \n",
       "4    324.546318  149.717165  6074.859475  257.432377  82.213495  0.536467   \n",
       "..          ...         ...          ...         ...        ...       ...   \n",
       "612  167.877117   27.287375   365.516874  257.432377  41.368691  0.691257   \n",
       "613  285.628059  344.644105   505.006814  257.432377  61.910576  0.772304   \n",
       "614  178.661133  103.988995  2083.880500  257.432377  90.411867  0.708616   \n",
       "615  119.162529         NaN   722.377629  257.432377  12.499760  0.602254   \n",
       "616  306.127863    6.090490   747.474930  257.432377  67.222974  0.644837   \n",
       "\n",
       "             CD         CF        CH        CL        CR         CS        CU  \\\n",
       "0     23.387600   4.851915  0.023482  1.050225  0.069225  13.784111  1.302012   \n",
       "1     50.628208   6.085041  0.031442  1.113875  1.117800  28.310953  1.357182   \n",
       "2     85.955376   5.376488  0.036218  1.050225  0.700350  39.364743  1.009611   \n",
       "3     88.159360   2.347652  0.029054  1.400300  0.636075  41.116960  0.722727   \n",
       "4     72.644264  30.537722  0.025472  1.050225  0.693150  31.724726  0.827550   \n",
       "..          ...        ...       ...       ...       ...        ...       ...   \n",
       "612   55.163024   4.780452  0.013930  1.177525  0.698250  40.159779  1.070298   \n",
       "613   85.233928   6.682597  0.038208  1.050225  0.761025  39.852923  2.146113   \n",
       "614  142.680216   7.809288  0.027462  1.495775  0.879825  39.364743  1.489590   \n",
       "615  122.939496   2.964975  0.022288  1.050225  0.583125  34.367872  1.428903   \n",
       "616  271.240664  10.479286  0.076018  1.241175  2.404275  42.799438  0.915822   \n",
       "\n",
       "            CW         DA          DE        DF        DH          DI  \\\n",
       "0    36.205956   69.08340  295.570575  0.238680  0.284232   89.245560   \n",
       "1    37.476568   70.79836  178.553100  0.238680  0.363489  110.581815   \n",
       "2    21.459644   70.81970  321.426625  0.238680  0.210441  120.056438   \n",
       "3    21.530392   47.27586  196.607985  0.238680  0.292431  139.824570   \n",
       "4    34.415360   74.06532  200.178160  0.238680  0.207708   97.920120   \n",
       "..         ...        ...         ...       ...       ...         ...   \n",
       "612   7.030640   21.75904  355.930925  0.238680  0.445479  176.977590   \n",
       "613  33.648356   43.90996  157.393715  0.238680  0.437280  192.598575   \n",
       "614  36.807176  104.62032  223.209115  0.238680  0.382620  218.915925   \n",
       "615  36.699352   51.04140  112.196630  0.532818  0.549333  113.526045   \n",
       "616  37.824144   35.72704  889.496905  0.238680  0.172179  156.345390   \n",
       "\n",
       "            DL         DN        DU       DV         DY         EB        EE  \\\n",
       "0     84.31664  29.657104  5.310690  1.74307  23.187704   7.294176  1.987283   \n",
       "1     75.74548  37.532000  0.005518  1.74307  17.222328   4.926396  0.858603   \n",
       "2     65.46984  28.053464  1.289739  1.74307  36.861352   7.813674  8.146651   \n",
       "3     71.57120  24.354856  2.655345  1.74307  52.003884   7.386060  3.813326   \n",
       "4     52.83888  26.019912  1.144902  1.74307   9.064856   7.350720  3.490846   \n",
       "..         ...        ...       ...      ...        ...        ...       ...   \n",
       "612   90.91832  27.957928  0.005518  2.41906  32.508604   8.015112  1.354416   \n",
       "613  123.17624  26.750080  0.648318  1.74307  18.197092   8.976360  0.753797   \n",
       "614  326.23620  26.463472  0.005518  1.74307  47.552312   9.478188  2.225112   \n",
       "615   96.97092  27.104928  0.510378  1.74307  38.271840  10.078968  1.628524   \n",
       "616   82.54008  21.086160  0.005518  1.74307  24.499368   7.873752  2.374259   \n",
       "\n",
       "               EG        EH  EJ          EL          EP          EU  \\\n",
       "0     1433.166750  0.949104   1   30.879420   78.526968    3.828384   \n",
       "1     1111.287150  0.003042   0  109.125159   95.415086   52.260480   \n",
       "2     1494.076488  0.377208   1  109.125159   78.526968    5.390628   \n",
       "3    15691.552180  0.614484   1   31.674357   78.526968   31.323372   \n",
       "4     1403.656300  0.164268   1  109.125159   91.994825   51.141336   \n",
       "..            ...       ...  ..         ...         ...         ...   \n",
       "612    495.086300  0.003042   0   51.618996   78.526968   65.821872   \n",
       "613   1722.674025  0.139932   1  109.125159  114.801199  447.657600   \n",
       "614   2565.402825  0.003042   0  109.125159   87.397401    3.828384   \n",
       "615   1318.962875  0.139932   1         NaN   99.706633    8.259384   \n",
       "616    912.311525  0.003042   0   15.960087  181.218219   78.370464   \n",
       "\n",
       "             FC         FD            FE         FI         FL        FR  \\\n",
       "0     13.394640  10.265073   9028.291921   3.583450   7.298162   1.73855   \n",
       "1     17.175984   0.296850   6785.003474  10.358927   0.173229   0.49706   \n",
       "2    224.207424   8.745201   8338.906181  11.626917   7.709560   0.97556   \n",
       "3     59.301984   7.884336  10965.766040  14.852022   6.122162   0.49706   \n",
       "4     29.102640   4.274640  16198.049590  13.666727   8.153058  48.50134   \n",
       "..          ...        ...           ...        ...        ...       ...   \n",
       "612   29.708112   0.296850  17167.209610   9.879296   0.173229   1.26092   \n",
       "613   69.343680   6.067614  18460.330020  10.910227  10.223150   1.24236   \n",
       "614   71.725584   0.296850   5088.922912  12.029366   0.173229   0.49706   \n",
       "615   38.133312   6.192291   6464.250832   8.026928   9.256996   0.78764   \n",
       "616   66.893232   0.296850   5895.352262   7.745765   0.173229   1.14492   \n",
       "\n",
       "           FS         GB          GE            GF         GH          GI  \\\n",
       "0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944   \n",
       "1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n",
       "2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n",
       "3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n",
       "4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n",
       "..        ...        ...         ...           ...        ...         ...   \n",
       "612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n",
       "613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n",
       "614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n",
       "615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n",
       "616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n",
       "\n",
       "            GL  Class  Alpha_A  Alpha_B  Alpha_D  Alpha_G  Beta_A  Beta_B  \\\n",
       "0     0.120343      1        0        1        0        0       0       0   \n",
       "1    21.978000      0        1        0        0        0       0       0   \n",
       "2     0.196941      0        1        0        0        0       0       0   \n",
       "3     0.155829      0        1        0        0        0       0       0   \n",
       "4     0.096614      1        0        0        1        0       0       1   \n",
       "..         ...    ...      ...      ...      ...      ...     ...     ...   \n",
       "612  21.978000      0        1        0        0        0       0       1   \n",
       "613   0.145340      0        1        0        0        0       0       1   \n",
       "614  21.978000      0        1        0        0        0       0       0   \n",
       "615   0.184622      0        1        0        0        0       0       0   \n",
       "616  21.978000      0        1        0        0        0       0       0   \n",
       "\n",
       "     Beta_C  Gamma_A  Gamma_B  Gamma_E  Gamma_F  Gamma_G  Gamma_H  Gamma_M  \\\n",
       "0         1        0        0        0        0        1        0        0   \n",
       "1         1        0        0        0        0        0        0        1   \n",
       "2         1        0        0        0        0        0        0        1   \n",
       "3         1        0        0        0        0        0        0        1   \n",
       "4         0        0        0        0        1        0        0        0   \n",
       "..      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "612       0        0        0        0        0        0        0        1   \n",
       "613       0        0        0        0        0        0        0        1   \n",
       "614       1        0        0        0        0        0        0        1   \n",
       "615       1        0        0        0        0        0        0        1   \n",
       "616       1        0        0        0        0        0        0        1   \n",
       "\n",
       "     Gamma_N  Delta_A  Delta_B  Delta_C  Delta_D  \n",
       "0          0        0        0        0        1  \n",
       "1          0        0        1        0        0  \n",
       "2          0        0        1        0        0  \n",
       "3          0        0        1        0        0  \n",
       "4          0        0        1        0        0  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "612        0        0        1        0        0  \n",
       "613        0        0        1        0        0  \n",
       "614        0        0        1        0        0  \n",
       "615        0        0        1        0        0  \n",
       "616        0        0        1        0        0  \n",
       "\n",
       "[617 rows x 77 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path = \"../data/raw\"\n",
    "\n",
    "train = pd.read_csv(f\"{input_path}/train.csv\")\n",
    "test  = pd.read_csv(f\"{input_path}/test.csv\")\n",
    "greeks = pd.read_csv(f\"{input_path}/greeks.csv\")\n",
    "\n",
    "train.columns = [col.strip() for col in train.columns]\n",
    "test.columns = [col.strip() for col in test.columns]\n",
    "\n",
    "# available features\n",
    "input_cols = train.columns[1:-1]\n",
    "categ_cols = [\"EJ\"]\n",
    "\n",
    "# we extend train with dummies from greeks\n",
    "dummies = pd.get_dummies(greeks[[\"Alpha\",\"Beta\",\"Gamma\",\"Delta\"]])\n",
    "train[dummies.columns] = dummies\n",
    "\n",
    "# encode of categorical features\n",
    "encoder = preprocessing.LabelEncoder().fit(train[\"EJ\"])\n",
    "train[\"EJ\"] = encoder.transform(train[\"EJ\"]).astype(int)\n",
    "test[\"EJ\"] = encoder.transform(test[\"EJ\"]).astype(int)\n",
    "\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7fd851-e720-4080-bce7-416e45c63955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.205745Z",
     "iopub.status.busy": "2023-08-08T22:45:49.204792Z",
     "iopub.status.idle": "2023-08-08T22:45:49.231499Z",
     "shell.execute_reply": "2023-08-08T22:45:49.230725Z"
    },
    "papermill": {
     "duration": 0.034132,
     "end_time": "2023-08-08T22:45:49.233491",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.199359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = impute.SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(train[input_cols])\n",
    "train[input_cols] = imputer.transform(train[input_cols])\n",
    "test[input_cols] = imputer.transform(test[input_cols])\n",
    "\n",
    "#scaler = preprocessing.MaxAbsScaler()\n",
    "#scaler.fit(train[input_cols])\n",
    "#train[input_cols] = scaler.transform(train[input_cols])\n",
    "#test[input_cols] = scaler.transform(test[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a5870a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.243681Z",
     "iopub.status.busy": "2023-08-08T22:45:49.243165Z",
     "iopub.status.idle": "2023-08-08T22:45:49.252927Z",
     "shell.execute_reply": "2023-08-08T22:45:49.252257Z"
    },
    "papermill": {
     "duration": 0.016781,
     "end_time": "2023-08-08T22:45:49.254538",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.237757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "repeated_cv_split = joblib.load(\"../data/iarc-data-split/repeated_5fold_cv_split_4tuning.pkl\")\n",
    "print(len(repeated_cv_split))\n",
    "\n",
    "# number of repetitions to use\n",
    "REPETITIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:05:50.036679Z",
     "iopub.status.busy": "2023-06-09T16:05:50.036272Z",
     "iopub.status.idle": "2023-06-09T16:05:50.061002Z",
     "shell.execute_reply": "2023-06-09T16:05:50.059984Z",
     "shell.execute_reply.started": "2023-06-09T16:05:50.036650Z"
    },
    "papermill": {
     "duration": 0.004317,
     "end_time": "2023-08-08T22:45:49.263274",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.258957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3473651c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.274203Z",
     "iopub.status.busy": "2023-08-08T22:45:49.273205Z",
     "iopub.status.idle": "2023-08-08T22:45:49.278609Z",
     "shell.execute_reply": "2023-08-08T22:45:49.277869Z"
    },
    "papermill": {
     "duration": 0.012653,
     "end_time": "2023-08-08T22:45:49.280207",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.267554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balanced_logloss_(y_pred, y_true):\n",
    "    n0 = np.sum(1-y_true)\n",
    "    n1 = np.sum(y_true)\n",
    "    p1 = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    p0 = 1-p1\n",
    "    log_loss0 = - np.sum((1-y_true) * np.log(p0)) / n0\n",
    "    log_loss1 = - np.sum(y_true * np.log(p1)) / n1\n",
    "    return (log_loss0 + log_loss1)/2\n",
    "\n",
    "#def balanced_logloss(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "#    y_true = data.get_label()\n",
    "#    return 'balanced_logloss', balanced_logloss_(y_pred, y_true), False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8d4a43f-6d48-4e04-869d-f8b4387452a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.290774Z",
     "iopub.status.busy": "2023-08-08T22:45:49.289868Z",
     "iopub.status.idle": "2023-08-08T22:45:49.296729Z",
     "shell.execute_reply": "2023-08-08T22:45:49.296099Z"
    },
    "papermill": {
     "duration": 0.013795,
     "end_time": "2023-08-08T22:45:49.298277",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.284482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 4.712962962962963\n",
      "neg_bagging_fraction: 0.21218074656188604\n"
     ]
    }
   ],
   "source": [
    "pct = train.Class.value_counts(normalize=True)\n",
    "scale_pos_weight = pct[0]/pct[1]\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "cnt = train.Class.value_counts(normalize=False)\n",
    "neg_bagging_fraction = cnt[1]/cnt[0]\n",
    "print(\"neg_bagging_fraction:\", neg_bagging_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f39cbdb-9907-4eb4-9937-e797c36f9f93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.309373Z",
     "iopub.status.busy": "2023-08-08T22:45:49.308786Z",
     "iopub.status.idle": "2023-08-08T22:45:49.317523Z",
     "shell.execute_reply": "2023-08-08T22:45:49.316637Z"
    },
    "papermill": {
     "duration": 0.016144,
     "end_time": "2023-08-08T22:45:49.319137",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.302993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    'device':'cpu',\n",
    "    'seed':2112,\n",
    "    'no_preprocess_mode':False,   \n",
    "}\n",
    "\n",
    "def train_validate(\n",
    "        dataframe,\n",
    "        input_cols, \n",
    "        model_params,\n",
    "        repeated_cv_split,\n",
    "        n_repetitions=REPETITIONS,\n",
    "        verbose=False,\n",
    "    ):\n",
    "\n",
    "    metrics = list()\n",
    "    model_params = dict(model_params)\n",
    "\n",
    "    for repeat in range(n_repetitions):\n",
    "        if verbose:\n",
    "            print(f\"REPEAT NUMBER: {repeat+1}/{n_repetitions}\")\n",
    "        cv_split = repeated_cv_split[f\"repeat_{repeat}\"]\n",
    "        n_folds = len(cv_split)\n",
    "        \n",
    "        for split in cv_split:\n",
    "            fold = split[\"fold\"]\n",
    "            train_idx = split[\"train_idx\"]\n",
    "            valid_idx = split[\"valid_idx\"]\n",
    "            if verbose:\n",
    "                print(f\"training model for fold: {fold+1}/{n_folds}\")\n",
    "        \n",
    "            train_df = dataframe.loc[train_idx,:].reset_index(drop=True)\n",
    "            valid_df = dataframe.loc[valid_idx,:].reset_index(drop=True)\n",
    "\n",
    "            clf = TabPFNClassifier(**model_params)\n",
    "            clf.fit(\n",
    "                train_df[input_cols].values, \n",
    "                train_df[\"Class\"].values, \n",
    "                overwrite_warning=True\n",
    "            )\n",
    "            y_pred = clf.predict_proba(valid_df[input_cols].values)\n",
    "\n",
    "            metrics.append( balanced_logloss_(y_pred[:,1], valid_df[\"Class\"].values) )\n",
    "    \n",
    "    return np.mean(metrics), np.std(metrics)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    _model_params = dict(\n",
    "        N_ensemble_configurations = trial.suggest_int(\"N_ensemble_configurations\", 4, 48),\n",
    "        multiclass_decoder = trial.suggest_categorical(\"multiclass_decoder\", [\"permutation\", \"\"]),\n",
    "        feature_shift_decoder = trial.suggest_categorical(\"feature_shift_decoder\", [True, False]),\n",
    "    )\n",
    "    model_params = {**DEFAULT_PARAMS, **_model_params}\n",
    "    \n",
    "    metric_mean, metric_std = train_validate(\n",
    "        dataframe = train,\n",
    "        input_cols = input_cols,\n",
    "        model_params = model_params,\n",
    "        repeated_cv_split = repeated_cv_split,\n",
    "        n_repetitions = REPETITIONS,\n",
    "        verbose = False,\n",
    "    )\n",
    "    \n",
    "    return metric_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1ce92b-0991-4967-8f51-f27d31fbcfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:45:49.330146Z",
     "iopub.status.busy": "2023-08-08T22:45:49.329485Z",
     "iopub.status.idle": "2023-08-08T22:46:28.364248Z",
     "shell.execute_reply": "2023-08-08T22:46:28.363319Z"
    },
    "papermill": {
     "duration": 39.042641,
     "end_time": "2023-08-08T22:46:28.366272",
     "exception": false,
     "start_time": "2023-08-08T22:45:49.323631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 47s, sys: 2.22 s, total: 4min 49s\n",
      "Wall time: 39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36983149081359734, 0.11315270521417865)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_validate(\n",
    "    dataframe = train,\n",
    "    input_cols = input_cols,\n",
    "    model_params = dict(N_ensemble_configurations=4, ),\n",
    "    repeated_cv_split = repeated_cv_split,\n",
    "    n_repetitions = REPETITIONS,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea38970c-522c-4506-9ed8-a0b04401593c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T22:46:28.387553Z",
     "iopub.status.busy": "2023-08-08T22:46:28.387196Z",
     "iopub.status.idle": "2023-08-08T23:50:00.829015Z",
     "shell.execute_reply": "2023-08-08T23:50:00.828256Z"
    },
    "papermill": {
     "duration": 3812.454589,
     "end_time": "2023-08-08T23:50:00.830739",
     "exception": false,
     "start_time": "2023-08-08T22:46:28.376150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:46:28,704] A new study created in RDB with name: iarc-tabpfn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:49:05,521] Trial 0 finished with value: 0.39235424043967077 and parameters: {'N_ensemble_configurations': 32, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 0 with value: 0.39235424043967077.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:52:02,870] Trial 1 finished with value: 0.3830388807346 and parameters: {'N_ensemble_configurations': 40, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 1 with value: 0.3830388807346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:52:40,267] Trial 2 finished with value: 0.39269619007030265 and parameters: {'N_ensemble_configurations': 4, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 1 with value: 0.3830388807346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:55:37,555] Trial 3 finished with value: 0.39285469150299257 and parameters: {'N_ensemble_configurations': 40, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 1 with value: 0.3830388807346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:56:17,595] Trial 4 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 24, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:58:37,255] Trial 5 finished with value: 0.38404552735196335 and parameters: {'N_ensemble_configurations': 28, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:59:10,593] Trial 6 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 12, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 22:59:44,559] Trial 7 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 20, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:00:18,180] Trial 8 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 44, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:02:10,979] Trial 9 finished with value: 0.3822663135093645 and parameters: {'N_ensemble_configurations': 24, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:05:22,283] Trial 10 finished with value: 0.3815979746244389 and parameters: {'N_ensemble_configurations': 44, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:05:54,811] Trial 11 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 8, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:06:33,451] Trial 12 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 40, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:08:14,967] Trial 13 finished with value: 0.39352149848431617 and parameters: {'N_ensemble_configurations': 20, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:08:53,600] Trial 14 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 48, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:10:15,900] Trial 15 finished with value: 0.3946768026996291 and parameters: {'N_ensemble_configurations': 16, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:11:37,771] Trial 16 finished with value: 0.38441116727247765 and parameters: {'N_ensemble_configurations': 16, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:12:16,576] Trial 17 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 16, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:12:49,371] Trial 18 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 40, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:15:05,435] Trial 19 finished with value: 0.39261899965218566 and parameters: {'N_ensemble_configurations': 28, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:15:43,401] Trial 20 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 32, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:16:15,645] Trial 21 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 24, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:17:15,967] Trial 22 finished with value: 0.38351107418750374 and parameters: {'N_ensemble_configurations': 12, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:20:45,405] Trial 23 finished with value: 0.3932007121842169 and parameters: {'N_ensemble_configurations': 48, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:21:17,191] Trial 24 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 48, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:23:07,766] Trial 25 finished with value: 0.3929391028997168 and parameters: {'N_ensemble_configurations': 24, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:23:39,241] Trial 26 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 32, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:26:26,018] Trial 27 finished with value: 0.3831302773811933 and parameters: {'N_ensemble_configurations': 36, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:28:04,450] Trial 28 finished with value: 0.3827086281142259 and parameters: {'N_ensemble_configurations': 20, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:28:42,125] Trial 29 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 28, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:31:27,716] Trial 30 finished with value: 0.3921391382764838 and parameters: {'N_ensemble_configurations': 36, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:32:05,054] Trial 31 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 4, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:32:54,662] Trial 32 finished with value: 0.39615769823763763 and parameters: {'N_ensemble_configurations': 8, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:33:32,497] Trial 33 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 20, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:34:10,502] Trial 34 finished with value: 0.38371038728064055 and parameters: {'N_ensemble_configurations': 4, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:35:10,490] Trial 35 finished with value: 0.39522181712996657 and parameters: {'N_ensemble_configurations': 12, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:35:48,214] Trial 36 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 12, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:39:18,186] Trial 37 finished with value: 0.38129305997183044 and parameters: {'N_ensemble_configurations': 48, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:39:50,085] Trial 38 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 36, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:40:27,932] Trial 39 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 36, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:41:17,701] Trial 40 finished with value: 0.38819448902186393 and parameters: {'N_ensemble_configurations': 8, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:41:49,588] Trial 41 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 28, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:42:27,654] Trial 42 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 8, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:42:59,866] Trial 43 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 4, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:46:09,758] Trial 44 finished with value: 0.39341216692527814 and parameters: {'N_ensemble_configurations': 44, 'feature_shift_decoder': True, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:46:42,063] Trial 45 finished with value: 0.39176687029643475 and parameters: {'N_ensemble_configurations': 16, 'feature_shift_decoder': False, 'multiclass_decoder': ''}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:47:24,589] Trial 46 finished with value: 0.3793298538759977 and parameters: {'N_ensemble_configurations': 44, 'feature_shift_decoder': False, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-08 23:50:00,680] Trial 47 finished with value: 0.38371446259748276 and parameters: {'N_ensemble_configurations': 32, 'feature_shift_decoder': True, 'multiclass_decoder': 'permutation'}. Best is trial 4 with value: 0.3793298538759977.\n"
     ]
    }
   ],
   "source": [
    "do_optimize = True\n",
    "\n",
    "search_space = {\n",
    "    'N_ensemble_configurations': list(range(4,49,4)),\n",
    "    \"multiclass_decoder\": [\"permutation\", \"\"],\n",
    "    \"feature_shift_decoder\": [True, False],\n",
    "}\n",
    "study = optuna.create_study(\n",
    "    study_name=\"iarc-tabpfn\",\n",
    "    direction='minimize',\n",
    "    storage='sqlite:///iarc-tabpfn.db',\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.GridSampler(search_space),\n",
    ")\n",
    "\n",
    "if do_optimize:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=10_000, \n",
    "        timeout=43200, # 12 hours\n",
    "        n_jobs=1, \n",
    "        gc_after_trial=True,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af4fee2-c3d4-4e1a-9854-d5a74865e060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:01.269530Z",
     "iopub.status.busy": "2023-08-08T23:50:01.269138Z",
     "iopub.status.idle": "2023-08-08T23:50:01.317495Z",
     "shell.execute_reply": "2023-08-08T23:50:01.316739Z"
    },
    "papermill": {
     "duration": 0.274026,
     "end_time": "2023-08-08T23:50:01.319343",
     "exception": false,
     "start_time": "2023-08-08T23:50:01.045317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_N_ensemble_configurations</th>\n",
       "      <th>params_feature_shift_decoder</th>\n",
       "      <th>params_multiclass_decoder</th>\n",
       "      <th>system_attrs_grid_id</th>\n",
       "      <th>system_attrs_search_space</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:35:10.642902</td>\n",
       "      <td>2023-08-08 23:35:48.199455</td>\n",
       "      <td>0 days 00:00:37.556553</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>10</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:11:37.920712</td>\n",
       "      <td>2023-08-08 23:12:16.559250</td>\n",
       "      <td>0 days 00:00:38.638538</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>14</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:46:42.211609</td>\n",
       "      <td>2023-08-08 23:47:24.569601</td>\n",
       "      <td>0 days 00:00:42.357992</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>42</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:08:15.153043</td>\n",
       "      <td>2023-08-08 23:08:53.581239</td>\n",
       "      <td>0 days 00:00:38.428196</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>46</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:41:49.736959</td>\n",
       "      <td>2023-08-08 23:42:27.640117</td>\n",
       "      <td>0 days 00:00:37.903158</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>6</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:05:54.992647</td>\n",
       "      <td>2023-08-08 23:06:33.436236</td>\n",
       "      <td>0 days 00:00:38.443589</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>38</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:39:50.236351</td>\n",
       "      <td>2023-08-08 23:40:27.916374</td>\n",
       "      <td>0 days 00:00:37.680023</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>34</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:15:05.594504</td>\n",
       "      <td>2023-08-08 23:15:43.386229</td>\n",
       "      <td>0 days 00:00:37.791725</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>30</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:28:04.615075</td>\n",
       "      <td>2023-08-08 23:28:42.110709</td>\n",
       "      <td>0 days 00:00:37.495634</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>26</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:31:27.866397</td>\n",
       "      <td>2023-08-08 23:32:05.038926</td>\n",
       "      <td>0 days 00:00:37.172529</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>2</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 22:55:37.710044</td>\n",
       "      <td>2023-08-08 22:56:17.580425</td>\n",
       "      <td>0 days 00:00:39.870381</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>22</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.379330</td>\n",
       "      <td>2023-08-08 23:32:54.820216</td>\n",
       "      <td>2023-08-08 23:33:32.481770</td>\n",
       "      <td>0 days 00:00:37.661554</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>permutation</td>\n",
       "      <td>18</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.381293</td>\n",
       "      <td>2023-08-08 23:35:48.364272</td>\n",
       "      <td>2023-08-08 23:39:18.171669</td>\n",
       "      <td>0 days 00:03:29.807397</td>\n",
       "      <td>48</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>44</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.381598</td>\n",
       "      <td>2023-08-08 23:02:11.164896</td>\n",
       "      <td>2023-08-08 23:05:22.266609</td>\n",
       "      <td>0 days 00:03:11.101713</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>40</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.382266</td>\n",
       "      <td>2023-08-08 23:00:18.356823</td>\n",
       "      <td>2023-08-08 23:02:10.962215</td>\n",
       "      <td>0 days 00:01:52.605392</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>20</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.382709</td>\n",
       "      <td>2023-08-08 23:26:26.174776</td>\n",
       "      <td>2023-08-08 23:28:04.434518</td>\n",
       "      <td>0 days 00:01:38.259742</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>16</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.383039</td>\n",
       "      <td>2023-08-08 22:49:05.668504</td>\n",
       "      <td>2023-08-08 22:52:02.854075</td>\n",
       "      <td>0 days 00:02:57.185571</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>36</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.383130</td>\n",
       "      <td>2023-08-08 23:23:39.395743</td>\n",
       "      <td>2023-08-08 23:26:26.001978</td>\n",
       "      <td>0 days 00:02:46.606235</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>32</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.383511</td>\n",
       "      <td>2023-08-08 23:16:15.791714</td>\n",
       "      <td>2023-08-08 23:17:15.952098</td>\n",
       "      <td>0 days 00:01:00.160384</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>8</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.383710</td>\n",
       "      <td>2023-08-08 23:33:32.646765</td>\n",
       "      <td>2023-08-08 23:34:10.482885</td>\n",
       "      <td>0 days 00:00:37.836120</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0</td>\n",
       "      <td>{'N_ensemble_configurations': [4, 8, 12, 16, 2...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "36      36  0.379330 2023-08-08 23:35:10.642902 2023-08-08 23:35:48.199455   \n",
       "17      17  0.379330 2023-08-08 23:11:37.920712 2023-08-08 23:12:16.559250   \n",
       "46      46  0.379330 2023-08-08 23:46:42.211609 2023-08-08 23:47:24.569601   \n",
       "14      14  0.379330 2023-08-08 23:08:15.153043 2023-08-08 23:08:53.581239   \n",
       "42      42  0.379330 2023-08-08 23:41:49.736959 2023-08-08 23:42:27.640117   \n",
       "12      12  0.379330 2023-08-08 23:05:54.992647 2023-08-08 23:06:33.436236   \n",
       "39      39  0.379330 2023-08-08 23:39:50.236351 2023-08-08 23:40:27.916374   \n",
       "20      20  0.379330 2023-08-08 23:15:05.594504 2023-08-08 23:15:43.386229   \n",
       "29      29  0.379330 2023-08-08 23:28:04.615075 2023-08-08 23:28:42.110709   \n",
       "31      31  0.379330 2023-08-08 23:31:27.866397 2023-08-08 23:32:05.038926   \n",
       "4        4  0.379330 2023-08-08 22:55:37.710044 2023-08-08 22:56:17.580425   \n",
       "33      33  0.379330 2023-08-08 23:32:54.820216 2023-08-08 23:33:32.481770   \n",
       "37      37  0.381293 2023-08-08 23:35:48.364272 2023-08-08 23:39:18.171669   \n",
       "10      10  0.381598 2023-08-08 23:02:11.164896 2023-08-08 23:05:22.266609   \n",
       "9        9  0.382266 2023-08-08 23:00:18.356823 2023-08-08 23:02:10.962215   \n",
       "28      28  0.382709 2023-08-08 23:26:26.174776 2023-08-08 23:28:04.434518   \n",
       "1        1  0.383039 2023-08-08 22:49:05.668504 2023-08-08 22:52:02.854075   \n",
       "27      27  0.383130 2023-08-08 23:23:39.395743 2023-08-08 23:26:26.001978   \n",
       "22      22  0.383511 2023-08-08 23:16:15.791714 2023-08-08 23:17:15.952098   \n",
       "34      34  0.383710 2023-08-08 23:33:32.646765 2023-08-08 23:34:10.482885   \n",
       "\n",
       "                 duration  params_N_ensemble_configurations  \\\n",
       "36 0 days 00:00:37.556553                                12   \n",
       "17 0 days 00:00:38.638538                                16   \n",
       "46 0 days 00:00:42.357992                                44   \n",
       "14 0 days 00:00:38.428196                                48   \n",
       "42 0 days 00:00:37.903158                                 8   \n",
       "12 0 days 00:00:38.443589                                40   \n",
       "39 0 days 00:00:37.680023                                36   \n",
       "20 0 days 00:00:37.791725                                32   \n",
       "29 0 days 00:00:37.495634                                28   \n",
       "31 0 days 00:00:37.172529                                 4   \n",
       "4  0 days 00:00:39.870381                                24   \n",
       "33 0 days 00:00:37.661554                                20   \n",
       "37 0 days 00:03:29.807397                                48   \n",
       "10 0 days 00:03:11.101713                                44   \n",
       "9  0 days 00:01:52.605392                                24   \n",
       "28 0 days 00:01:38.259742                                20   \n",
       "1  0 days 00:02:57.185571                                40   \n",
       "27 0 days 00:02:46.606235                                36   \n",
       "22 0 days 00:01:00.160384                                12   \n",
       "34 0 days 00:00:37.836120                                 4   \n",
       "\n",
       "    params_feature_shift_decoder params_multiclass_decoder  \\\n",
       "36                         False               permutation   \n",
       "17                         False               permutation   \n",
       "46                         False               permutation   \n",
       "14                         False               permutation   \n",
       "42                         False               permutation   \n",
       "12                         False               permutation   \n",
       "39                         False               permutation   \n",
       "20                         False               permutation   \n",
       "29                         False               permutation   \n",
       "31                         False               permutation   \n",
       "4                          False               permutation   \n",
       "33                         False               permutation   \n",
       "37                          True               permutation   \n",
       "10                          True               permutation   \n",
       "9                           True               permutation   \n",
       "28                          True               permutation   \n",
       "1                           True               permutation   \n",
       "27                          True               permutation   \n",
       "22                          True               permutation   \n",
       "34                          True               permutation   \n",
       "\n",
       "    system_attrs_grid_id                          system_attrs_search_space  \\\n",
       "36                    10  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "17                    14  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "46                    42  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "14                    46  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "42                     6  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "12                    38  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "39                    34  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "20                    30  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "29                    26  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "31                     2  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "4                     22  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "33                    18  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "37                    44  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "10                    40  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "9                     20  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "28                    16  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "1                     36  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "27                    32  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "22                     8  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "34                     0  {'N_ensemble_configurations': [4, 8, 12, 16, 2...   \n",
       "\n",
       "       state  \n",
       "36  COMPLETE  \n",
       "17  COMPLETE  \n",
       "46  COMPLETE  \n",
       "14  COMPLETE  \n",
       "42  COMPLETE  \n",
       "12  COMPLETE  \n",
       "39  COMPLETE  \n",
       "20  COMPLETE  \n",
       "29  COMPLETE  \n",
       "31  COMPLETE  \n",
       "4   COMPLETE  \n",
       "33  COMPLETE  \n",
       "37  COMPLETE  \n",
       "10  COMPLETE  \n",
       "9   COMPLETE  \n",
       "28  COMPLETE  \n",
       "1   COMPLETE  \n",
       "27  COMPLETE  \n",
       "22  COMPLETE  \n",
       "34  COMPLETE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318b0518-c689-4f08-b0cd-158e9087ae60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:01.776682Z",
     "iopub.status.busy": "2023-08-08T23:50:01.775721Z",
     "iopub.status.idle": "2023-08-08T23:50:03.388287Z",
     "shell.execute_reply": "2023-08-08T23:50:03.387376Z"
    },
    "papermill": {
     "duration": 1.839963,
     "end_time": "2023-08-08T23:50:03.390121",
     "exception": false,
     "start_time": "2023-08-08T23:50:01.550158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavillan/mambaforge/envs/kg/lib/python3.10/site-packages/kaleido/scopes/base.py:188: DeprecationWarning:\n",
      "\n",
      "setDaemon() is deprecated, set the daemon attribute instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf396a79-1638-45ba-b2f1-ace3c310260b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:03.856886Z",
     "iopub.status.busy": "2023-08-08T23:50:03.856500Z",
     "iopub.status.idle": "2023-08-08T23:50:04.308864Z",
     "shell.execute_reply": "2023-08-08T23:50:04.307925Z"
    },
    "papermill": {
     "duration": 0.687605,
     "end_time": "2023-08-08T23:50:04.310847",
     "exception": false,
     "start_time": "2023-08-08T23:50:03.623242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd2e02a-b799-4e04-9448-5a36a213efeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:04.808993Z",
     "iopub.status.busy": "2023-08-08T23:50:04.808680Z",
     "iopub.status.idle": "2023-08-08T23:50:05.132508Z",
     "shell.execute_reply": "2023-08-08T23:50:05.131847Z"
    },
    "papermill": {
     "duration": 0.551399,
     "end_time": "2023-08-08T23:50:05.134132",
     "exception": false,
     "start_time": "2023-08-08T23:50:04.582733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0890fba3-07cb-4889-9387-fcd4e3dbb884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:05.566465Z",
     "iopub.status.busy": "2023-08-08T23:50:05.565090Z",
     "iopub.status.idle": "2023-08-08T23:50:05.629761Z",
     "shell.execute_reply": "2023-08-08T23:50:05.628933Z"
    },
    "papermill": {
     "duration": 0.284148,
     "end_time": "2023-08-08T23:50:05.631574",
     "exception": false,
     "start_time": "2023-08-08T23:50:05.347426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a0f23b-e67e-4af1-b8aa-f25fd6b3519e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:06.106642Z",
     "iopub.status.busy": "2023-08-08T23:50:06.106282Z",
     "iopub.status.idle": "2023-08-08T23:50:07.710403Z",
     "shell.execute_reply": "2023-08-08T23:50:07.709639Z"
    },
    "papermill": {
     "duration": 1.861038,
     "end_time": "2023-08-08T23:50:07.712416",
     "exception": false,
     "start_time": "2023-08-08T23:50:05.851378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa53e62-a488-4f7e-99fa-c3d6c7b6689b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T23:50:08.159048Z",
     "iopub.status.busy": "2023-08-08T23:50:08.158103Z",
     "iopub.status.idle": "2023-08-08T23:50:08.170955Z",
     "shell.execute_reply": "2023-08-08T23:50:08.170317Z"
    },
    "papermill": {
     "duration": 0.236447,
     "end_time": "2023-08-08T23:50:08.172463",
     "exception": false,
     "start_time": "2023-08-08T23:50:07.936016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'seed': 2112,\n",
       " 'no_preprocess_mode': False,\n",
       " 'N_ensemble_configurations': 24,\n",
       " 'feature_shift_decoder': False,\n",
       " 'multiclass_decoder': 'permutation'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = dict(study.best_params)\n",
    "best_params = {**DEFAULT_PARAMS, **best_params}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6e7fd",
   "metadata": {
    "papermill": {
     "duration": 0.225782,
     "end_time": "2023-08-08T23:50:08.618014",
     "exception": false,
     "start_time": "2023-08-08T23:50:08.392232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3866.870417,
   "end_time": "2023-08-08T23:50:11.464469",
   "environment_variables": {},
   "exception": null,
   "input_path": "tuning/iarc-tabpfn.ipynb",
   "output_path": "tuning/outputs/iarc-tabpfn.ipynb",
   "parameters": {},
   "start_time": "2023-08-08T22:45:44.594052",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
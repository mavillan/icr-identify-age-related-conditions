{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e4da7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.806532,
     "end_time": "2023-06-15T16:40:06.936763",
     "exception": false,
     "start_time": "2023-06-15T16:40:04.130231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import impute\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_contour\n",
    "    , plot_edf\n",
    "    , plot_intermediate_values\n",
    "    , plot_optimization_history\n",
    "    , plot_parallel_coordinate\n",
    "    , plot_param_importances\n",
    "    , plot_slice\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b684f",
   "metadata": {
    "papermill": {
     "duration": 0.004786,
     "end_time": "2023-06-15T16:40:06.947030",
     "exception": false,
     "start_time": "2023-06-15T16:40:06.942244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b3296",
   "metadata": {
    "papermill": {
     "duration": 0.19407,
     "end_time": "2023-06-15T16:40:07.146144",
     "exception": false,
     "start_time": "2023-06-15T16:40:06.952074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = \"../data/raw\"\n",
    "\n",
    "train = pd.read_csv(f\"{input_path}/train.csv\")\n",
    "test  = pd.read_csv(f\"{input_path}/test.csv\")\n",
    "greeks = pd.read_csv(f\"{input_path}/greeks.csv\")\n",
    "\n",
    "train.columns = [col.strip() for col in train.columns]\n",
    "test.columns = [col.strip() for col in test.columns]\n",
    "\n",
    "# available features\n",
    "input_cols = train.columns[1:-1]\n",
    "categ_cols = [\"EJ\"]\n",
    "\n",
    "# we extend train with dummies from greeks\n",
    "dummies = pd.get_dummies(greeks[[\"Alpha\",\"Beta\",\"Gamma\",\"Delta\"]])\n",
    "train[dummies.columns] = dummies\n",
    "\n",
    "# encode of categorical features\n",
    "encoder = preprocessing.LabelEncoder().fit(train[\"EJ\"])\n",
    "train[\"EJ\"] = encoder.transform(train[\"EJ\"]).astype(int)\n",
    "test[\"EJ\"] = encoder.transform(test[\"EJ\"]).astype(int)\n",
    "\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7fd851-e720-4080-bce7-416e45c63955",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = impute.SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(train[input_cols])\n",
    "train[input_cols] = imputer.transform(train[input_cols])\n",
    "test[input_cols] = imputer.transform(test[input_cols])\n",
    "\n",
    "#scaler = preprocessing.MaxAbsScaler()\n",
    "#scaler.fit(train[input_cols])\n",
    "#train[input_cols] = scaler.transform(train[input_cols])\n",
    "#test[input_cols] = scaler.transform(test[input_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5870a8",
   "metadata": {
    "papermill": {
     "duration": 0.044654,
     "end_time": "2023-06-15T16:40:07.198018",
     "exception": false,
     "start_time": "2023-06-15T16:40:07.153364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeated_cv_split = joblib.load(\"../data/iarc-data-split/repeated_5fold_cv_split_4tuning.pkl\")\n",
    "print(len(repeated_cv_split))\n",
    "\n",
    "# number of repetitions to use\n",
    "REPETITIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T16:05:50.036679Z",
     "iopub.status.busy": "2023-06-09T16:05:50.036272Z",
     "iopub.status.idle": "2023-06-09T16:05:50.061002Z",
     "shell.execute_reply": "2023-06-09T16:05:50.059984Z",
     "shell.execute_reply.started": "2023-06-09T16:05:50.036650Z"
    },
    "papermill": {
     "duration": 0.006725,
     "end_time": "2023-06-15T16:40:07.211800",
     "exception": false,
     "start_time": "2023-06-15T16:40:07.205075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473651c",
   "metadata": {
    "papermill": {
     "duration": 0.018317,
     "end_time": "2023-06-15T16:40:07.236931",
     "exception": false,
     "start_time": "2023-06-15T16:40:07.218614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balanced_logloss_(y_pred, y_true):\n",
    "    n0 = np.sum(1-y_true)\n",
    "    n1 = np.sum(y_true)\n",
    "    p1 = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    p0 = 1-p1\n",
    "    log_loss0 = - np.sum((1-y_true) * np.log(p0)) / n0\n",
    "    log_loss1 = - np.sum(y_true * np.log(p1)) / n1\n",
    "    return (log_loss0 + log_loss1)/2\n",
    "\n",
    "#def balanced_logloss(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "#    y_true = data.get_label()\n",
    "#    return 'balanced_logloss', balanced_logloss_(y_pred, y_true), False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4a43f-6d48-4e04-869d-f8b4387452a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pct = train.Class.value_counts(normalize=True)\n",
    "scale_pos_weight = pct[0]/pct[1]\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "cnt = train.Class.value_counts(normalize=False)\n",
    "neg_bagging_fraction = cnt[1]/cnt[0]\n",
    "print(\"neg_bagging_fraction:\", neg_bagging_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39cbdb-9907-4eb4-9937-e797c36f9f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_validate(\n",
    "        dataframe,\n",
    "        input_cols, \n",
    "        model_params,\n",
    "        repeated_cv_split,\n",
    "        n_repetitions=REPETITIONS,\n",
    "        verbose=False,\n",
    "        scale_probs=False,\n",
    "    ):\n",
    "\n",
    "    metrics = list()\n",
    "    model_params = dict(model_params)\n",
    "\n",
    "    for repeat in range(n_repetitions):\n",
    "        if verbose:\n",
    "            print(f\"REPEAT NUMBER: {repeat+1}/{n_repetitions}\")\n",
    "        cv_split = repeated_cv_split[f\"repeat_{repeat}\"]\n",
    "        n_folds = len(cv_split)\n",
    "        \n",
    "        for split in cv_split:\n",
    "            fold = split[\"fold\"]\n",
    "            train_idx = split[\"train_idx\"]\n",
    "            valid_idx = split[\"valid_idx\"]\n",
    "            if verbose:\n",
    "                print(f\"training model for fold: {fold+1}/{n_folds}\")\n",
    "        \n",
    "            train_df = dataframe.loc[train_idx,:].reset_index(drop=True)\n",
    "            valid_df = dataframe.loc[valid_idx,:].reset_index(drop=True)\n",
    "\n",
    "            clf = TabPFNClassifier(**model_params)\n",
    "            clf.fit(\n",
    "                train_df[input_cols].values, \n",
    "                train_df[\"Class\"].values, \n",
    "                overwrite_warning=True\n",
    "            )\n",
    "            y_pred = clf.predict_proba(valid_df[input_cols].values)\n",
    "\n",
    "            if scale_probs:\n",
    "                y_pred = (y_pred / np.sum(y_pred, axis=0))\n",
    "                y_pred = (y_pred / np.sum(y_pred, axis=1, keepdims=1))\n",
    "\n",
    "            metrics.append( balanced_logloss_(y_pred[:,1], valid_df[\"Class\"].values) )\n",
    "    \n",
    "    return np.mean(metrics), np.std(metrics)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model_params = dict(\n",
    "        N_ensemble_configurations = 2**trial.suggest_int(\"N_ensemble_configurations_exp\", 2, 7),\n",
    "        no_preprocess_mode = trial.suggest_categorical(\"no_preprocess_mode\", [True, False]),\n",
    "        multiclass_decoder = trial.suggest_categorical(\"multiclass_decoder\", [\"permutation\", \"\"]),\n",
    "        feature_shift_decoder = trial.suggest_categorical(\"feature_shift_decoder\", [True, False]),\n",
    "        scale_probs = trial.suggest_categorical(\"scale_probs\", [True, False]),\n",
    "    )\n",
    "    scale_probs = model_params.pop(\"scale_probs\")\n",
    "    \n",
    "    metric_mean, metric_std = train_validate(\n",
    "        dataframe = train,\n",
    "        input_cols = input_cols,\n",
    "        model_params = model_params,\n",
    "        repeated_cv_split = repeated_cv_split,\n",
    "        n_repetitions = REPETITIONS,\n",
    "        verbose = False,\n",
    "        scale_probs = scale_probs,\n",
    "    )\n",
    "    \n",
    "    return metric_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ce92b-0991-4967-8f51-f27d31fbcfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_validate(\n",
    "    dataframe = train,\n",
    "    input_cols = input_cols,\n",
    "    model_params = dict(N_ensemble_configurations=4, ),\n",
    "    repeated_cv_split = repeated_cv_split,\n",
    "    n_repetitions = REPETITIONS,\n",
    "    verbose = False,\n",
    "    scale_probs = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38970c-522c-4506-9ed8-a0b04401593c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_optimize = True\n",
    "\n",
    "search_space = {\n",
    "    'N_ensemble_configurations_exp': [2,3,4,5,6,7],\n",
    "    'no_preprocess_mode': [True, False],\n",
    "    \"multiclass_decoder\": [\"permutation\", \"\"],\n",
    "    \"feature_shift_decoder\": [True, False],\n",
    "    \"scale_probs\": [True, False],\n",
    "}\n",
    "study = optuna.create_study(\n",
    "    study_name=\"iarc-tabpfn\",\n",
    "    direction='minimize',\n",
    "    storage='sqlite:///iarc-tabpfn.db',\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.GridSampler(search_space),\n",
    ")\n",
    "\n",
    "if do_optimize:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=10_000, \n",
    "        timeout=43200, # 12 hours\n",
    "        n_jobs=1, \n",
    "        gc_after_trial=True,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4fee2-c3d4-4e1a-9854-d5a74865e060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b0518-c689-4f08-b0cd-158e9087ae60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf396a79-1638-45ba-b2f1-ace3c310260b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2e02a-b799-4e04-9448-5a36a213efeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890fba3-07cb-4889-9387-fcd4e3dbb884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0f23b-e67e-4af1-b8aa-f25fd6b3519e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa53e62-a488-4f7e-99fa-c3d6c7b6689b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = dict(study.best_params)\n",
    "best_params[\"N_ensemble_configurations\"] = 2**best_params.pop(\"N_ensemble_configurations_exp\")\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6e7fd",
   "metadata": {
    "papermill": {
     "duration": 0.0756,
     "end_time": "2023-06-15T16:44:33.334089",
     "exception": false,
     "start_time": "2023-06-15T16:44:33.258489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 283.735312,
   "end_time": "2023-06-15T16:44:34.633717",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-15T16:39:50.898405",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
